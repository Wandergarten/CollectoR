{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "[HIDA] Hyperparameter_Tutorial_Part2_solution.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1-xSwPUN0Saa",
        "UeTAXZL70Sbj",
        "G-FVu-aU0Sbp",
        "-Jgb27jS0Sbv",
        "CX4oOamJ0ScO",
        "lH81bOVa0Sca"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wandergarten/CollectoR/blob/main/%5BHIDA%5D_Hyperparameter_Tutorial_Part2_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI69m7xV0SZW"
      },
      "source": [
        "# HDS-LEE Course on Hyperparameter Optimization - Part 2\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/DLR-SC/Hyperparameter_tutorial/master/img/hds_lee_title.png' width=500px>\n",
        "\n",
        "This notebook summarizes several examples from the Talos GitHub repository. The original examples can be found\n",
        "on https://github.com/autonomio/talos/tree/master/examples\n",
        "\n",
        "Note: The output of this notebook is not reproducible. This means that **the final\n",
        "output changes with every usage of the code**. There are two main reasons for this\n",
        "stochastic behavior:\n",
        "* the traing set is quite small (400 samples) to reduce computing time (this is a tutorial so that\n",
        "there is a limited amount of time)\n",
        "* we use a 'random hyperparameter search strategy' and only cover a small percentage \n",
        "of parameter configurations (about 1%) to reduce computing time so that the output, of course, is\n",
        "not deterministic.\n",
        "\n",
        "In practice, this stochastic behavior should be strongly reduced since the number\n",
        "of training samples is usually much larger and the 'random hyperparameter search strategy'\n",
        "usually covers a larger percentage of hyperparameter configurations. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfTg22Ok3tqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a429d3a-f072-4dc9-f6d7-743645e074aa"
      },
      "source": [
        "pip install talos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting talos\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/90/2455415b2a2170ad649b66d79ea74ff1af546c012836a2b621323a5fabfd/talos-1.0-py3-none-any.whl (53kB)\n",
            "\r\u001b[K     |██████                          | 10kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 20kB 16.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 2.9MB/s \n",
            "\u001b[?25hCollecting astetik\n",
            "  Downloading https://files.pythonhosted.org/packages/3c/ba/f8622951da73d9b47b45bb847112c388651f9c6e413e712954f260301d9f/astetik-1.9.9.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from talos) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from talos) (4.41.1)\n",
            "Collecting chances\n",
            "  Downloading https://files.pythonhosted.org/packages/fa/d8/d61112d7476dc3074b855f1edd8556cde9b49b7106853f0b060109dd4c82/chances-0.1.9.tar.gz\n",
            "Collecting kerasplotlib\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/b7/31663d3b5ea9afd8c2c6ffa06d3c4e118ef363e12dc75b7c49fb6a2d22aa/kerasplotlib-0.1.6.tar.gz\n",
            "Requirement already satisfied: tensorflow>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from talos) (2.3.0)\n",
            "Collecting statsmodels>=0.11.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/4c/9e2435ca6645d6bafa2b51bb11f0a365b28934a2ffe9d6e339d67130926d/statsmodels-0.12.1-cp36-cp36m-manylinux1_x86_64.whl (9.5MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5MB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from talos) (0.0)\n",
            "Collecting wrangle\n",
            "  Downloading https://files.pythonhosted.org/packages/85/35/bc729e377417613f2d062a890faea5d649ef1a554df21499e9c3a4a5501a/wrangle-0.6.7.tar.gz\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from talos) (1.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from talos) (1.18.5)\n",
            "Collecting geonamescache\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/ba/b7939087621bfeb24c0f52c4b879865a9f902cda72efd119f4275400e692/geonamescache-1.2.0-py3-none-any.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 39.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (2020.6.20)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from chances->talos) (1.4.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from kerasplotlib->talos) (5.5.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->talos) (3.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->talos) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->talos) (3.12.4)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->talos) (2.3.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->talos) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->talos) (0.10.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->talos) (2.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->talos) (2.3.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->talos) (1.6.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->talos) (0.35.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->talos) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->talos) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->talos) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->talos) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0.0->talos) (1.33.2)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.6/dist-packages (from statsmodels>=0.11.0->talos) (0.5.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->talos) (0.22.2.post1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from wrangle->talos) (2.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->talos) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->talos) (2018.9)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->kerasplotlib->talos) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->kerasplotlib->talos) (50.3.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->kerasplotlib->talos) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->kerasplotlib->talos) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->kerasplotlib->talos) (4.3.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->kerasplotlib->talos) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->kerasplotlib->talos) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->kerasplotlib->talos) (4.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0.0->talos) (1.17.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0.0->talos) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0.0->talos) (3.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0.0->talos) (0.4.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0.0->talos) (1.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->talos) (0.17.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->wrangle->talos) (3.13)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kerasplotlib->talos) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->kerasplotlib->talos) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->kerasplotlib->talos) (0.6.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.0.0->talos) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.0.0->talos) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.0.0->talos) (4.6)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.0.0->talos) (2.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.0.0->talos) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.0.0->talos) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.0.0->talos) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.0.0->talos) (3.1.0)\n",
            "Building wheels for collected packages: astetik, chances, kerasplotlib, wrangle\n",
            "  Building wheel for astetik (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for astetik: filename=astetik-1.9.9-cp36-none-any.whl size=56961 sha256=234ab1c9d9f4fb60d14b781e1fec5229581a7fc969291318b3fe1186f26f3698\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/70/21/c475cd079ec401dd6e1b9b1d42b4c38554ce12679bfb214aad\n",
            "  Building wheel for chances (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chances: filename=chances-0.1.9-cp36-none-any.whl size=41610 sha256=183f349a4181527e59ff09b200054ca6aef68fd56f1812e9ef55edce4c899278\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/33/46/c871b94249bd57d17797d049b3dff8e3a09c315afb67eb14c6\n",
            "  Building wheel for kerasplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kerasplotlib: filename=kerasplotlib-0.1.6-cp36-none-any.whl size=3603 sha256=53b2bad1b4698b38357c9b292af534fd104d0d65d9ee1598793c4272989679ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/d3/8c/9503a22b0a38e8b21c70ad834e4606d209193443e5c709305d\n",
            "  Building wheel for wrangle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrangle: filename=wrangle-0.6.7-cp36-none-any.whl size=49894 sha256=6fc8b33b31e4f104feeb60f67ffa9818f0348cb5253154ca130cf7d1faf71ed1\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/1b/50/d0403ce6ef269e364894da7b50db68db14c4ac62c577561e2d\n",
            "Successfully built astetik chances kerasplotlib wrangle\n",
            "\u001b[31mERROR: wrangle 0.6.7 has requirement scipy==1.2, but you'll have scipy 1.4.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: statsmodels, wrangle, geonamescache, astetik, chances, kerasplotlib, talos\n",
            "  Found existing installation: statsmodels 0.10.2\n",
            "    Uninstalling statsmodels-0.10.2:\n",
            "      Successfully uninstalled statsmodels-0.10.2\n",
            "Successfully installed astetik-1.9.9 chances-0.1.9 geonamescache-1.2.0 kerasplotlib-0.1.6 statsmodels-0.12.1 talos-1.0 wrangle-0.6.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7I90WeH0SZY"
      },
      "source": [
        "%matplotlib inline\n",
        "# required Talos __version__ = \"0.6.6\"\n",
        "import talos\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "zFAErOZI0SZg"
      },
      "source": [
        "## Overview\n",
        "\n",
        "The aim of the 2nd tutorial is the following:\n",
        "\n",
        "* Introduction of Talos\n",
        "* Use Talos for machine-assisted hyperparameter optimization of the Boston house pricing problem (1st Jupyter notebook).\n",
        "Also note that there is a large variety of hyperparameter tuning libraries and Talos is only\n",
        "one viable option (another recommend alternative is Keras Tuner)\n",
        "* Give general guidelines on hyperparameter optimization\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "##### 1. <a href=#one>Introduction of Talos</a>\n",
        "##### 2. <a href=#two>Use Talos for hyperparameter optimization </a>\n",
        "##### 3. <a href=#three>Guidelines on hyperparameter optimization</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn1CJTIf0SZh"
      },
      "source": [
        "## 1. Introduction of Talos <a name=\"one\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%% md\n"
        },
        "id": "j0E2uMKL0SZi"
      },
      "source": [
        "### Restore the original Keras code \n",
        "\n",
        "We start with the code that we have already used in the first notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "VDADRP7o0SZj"
      },
      "source": [
        "from keras.datasets import boston_housing\n",
        "\n",
        "# load the data\n",
        "(train_data, train_targets), (test_data, test_targets) =  boston_housing.load_data()\n",
        "\n",
        "# data normalization\n",
        "mean = train_data.mean(axis=0)\n",
        "train_data -= mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data /= std\n",
        "\n",
        "test_data -= mean\n",
        "test_data /= std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "_vA7ZRHv0SZp"
      },
      "source": [
        "### Model preparation\n",
        "\n",
        "Talos works with any Keras model, without changing the structure of the model in any way.  \n",
        "The only difference in the Keras model is that a parameter is not set explicitly as before, e.g.\n",
        "\n",
        "<pre><code> model.add(layers.Dense(32, activation='relu'))    </code></pre>\n",
        "\n",
        "but instead taken from a dictionary, e.g.\n",
        "\n",
        "<pre><code>\n",
        "params = {'number_of_neurons' : [4, 6, 7, 8], 'activation' : ['relu'] }\n",
        "\n",
        "model.add(layers.Dense(params['number_of_neurons'], activation=params['activation']))    \n",
        "</code></pre>\n",
        "\n",
        "Afterwards, this dictionary and the model will be passed to Talos. In the dictionary we have \n",
        "three different ways to input values:\n",
        "\n",
        "- as stepped ranges (min, max, steps) if the parameter is a floating point number\n",
        "- as multiple values [in a list]\n",
        "- as a single value [in a list]\n",
        "\n",
        "For values we don't want to use, it's ok to set it as None."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "H_Em62pJ0SZq"
      },
      "source": [
        "## Tasks ## \n",
        "__Excercise 1:__\n",
        " - Create a Python dictionary that contains at least the following entries:\n",
        "    * 'number_of_layers' : 1, 2\n",
        "    * 'number_of_neurons' : 8, 16, 32, 64\n",
        "    * 'dropout_value' : None, 0.1, 0.2\n",
        "    * 'optimizer' : 'Adam', 'rmsprop'\n",
        "    * 'batch_size': 1, 2, 4, 8 \n",
        "    * 'epoch_number' : 10, 20, 40, 80\n",
        "    * anything that you want to modify further (e.g. learning_rate, activation_function, loss_function, ...)\n",
        " - What is the number of different hyperparameter configurations that is considered in the first six bullet points?\n",
        " Answer: 768 different configurations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "x8YL9zlE0SZr"
      },
      "source": [
        "# parameter dictionary\n",
        "param = {'number_of_layers' : [1, 2],\n",
        "         'number_of_neurons' : [8, 16, 32, 64],\n",
        "         'epoch_number' : [10, 20, 40, 80],\n",
        "         'dropout_value' : [None, 0.1, 0.2],\n",
        "         'optimizer' : ['Adam', 'rmsprop'],\n",
        "         'batch_size' : [1, 2, 4, 8]}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "eP_3PaKN0SZx"
      },
      "source": [
        "## Tasks ## \n",
        "__Excercise 2:__\n",
        " - Modify your original Keras model (Jupyter notebook 1) such that it uses uses the values from a \n",
        " dictionary 'p'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ffCqPGh70SZy"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "# note: this build model works for a limited number of hidden layers, there are other options in Talos\n",
        "# if you are interested in a large number of layers (see: Outlook at the end of this tutorial)\n",
        "def build_better_model(x, y, val_data, val_targets, p):\n",
        "    model = models.Sequential()\n",
        "    \n",
        "    # replace the hyperparameter inputs with references to dictionary p \n",
        "    model.add(layers.Dense(p['number_of_neurons'], activation='relu',\n",
        "                           input_shape=(x.shape[1],)))\n",
        "    \n",
        "    if p['number_of_layers'] >= 2:\n",
        "        model.add(layers.Dense(p['number_of_neurons'], activation='relu'))\n",
        "    \n",
        "    if p['dropout_value'] is not None:\n",
        "        model.add(layers.Dropout(p['dropout_value']))\n",
        "        \n",
        "    model.add(layers.Dense(1))\n",
        "    model.compile(optimizer=p['optimizer'], loss='mse', metrics=['mae'])\n",
        "    \n",
        "    # make sure history object is returned by model.fit()\n",
        "    history = model.fit(x, y, epochs=p['epoch_number'], batch_size=p['batch_size'], verbose=0)\n",
        "    \n",
        "    return history, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "qY8c-Kbg0SZ3"
      },
      "source": [
        "## 2. Use Talos for hyperparameter optimization <a name=\"two\"></a> \n",
        "\n",
        "This part is quite simple. The Talos experiment just uses the <code> Scan()</code> command. In the following,\n",
        "we will investigate different arguments for this routine. However, there are only five necessary arguments\n",
        "that are required:\n",
        "* train_data (often known as 'x')\n",
        "* train_targets (often known as 'y')\n",
        "* params (the dictionary 'param' that we have created before)\n",
        "* model (the 'build_model' that we also have created before)\n",
        "* experiment_name (name of a folder in which the output, a csv-file, is stored)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OREiycNT0SZ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df0f6434-a03e-40e4-fd14-e2e2a79946f7"
      },
      "source": [
        "scan_object = talos.Scan(x=train_data,\n",
        "                         y=train_targets,\n",
        "                         model=build_better_model,\n",
        "                         experiment_name='find_optimal_params',\n",
        "                         params=param,\n",
        "                         round_limit=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:37<00:00,  3.72s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "U7DjrMhm0SZ-"
      },
      "source": [
        "If all different parameter configurations from the dictionary are used, the routine <code> Scan()</code> has to\n",
        "evaluate 768 different models. Depending on the neural network architecture and the number of training samples,\n",
        "this can be very time-consuming.\n",
        "\n",
        "As a solution, Talos offers several routines to limit the number of model configurations that is evaluated. Two useful\n",
        "commands of <code> Scan()</code> for this purpose are:\n",
        "\n",
        "* <code> round_limit=10</code> which limits the number of model evaluations to the specified integer value (e.g. \n",
        "10 model evaluations in this example).\n",
        "* <code> fraction_limit = 0.1</code> specifies the fraction of `params` that will be tested  (e.g. 10% of the \n",
        "configurations in this example).   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QileeFk90SZ_"
      },
      "source": [
        "### Access the results through the <code>Scan</code> object "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "CHOeffI00SaA"
      },
      "source": [
        "Using <code> round_limit=10</code> we have investigated only ten parameter configurations (about 1% of \n",
        "all possible configurations) since the time\n",
        "for this tutorial is limited. But what are ten configurations that have been used and what is their\n",
        "performance?\n",
        "\n",
        "For this purpose, the results of the scan object can be directly accessed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WNGFe8hp0SaB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "d38ebf15-b0de-4cb6-ab2a-4b1a01e3d349"
      },
      "source": [
        "# accessing the results data frame\n",
        "scan_object.data\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>duration</th>\n",
              "      <th>round_epochs</th>\n",
              "      <th>loss</th>\n",
              "      <th>mae</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>dropout_value</th>\n",
              "      <th>epoch_number</th>\n",
              "      <th>number_of_layers</th>\n",
              "      <th>number_of_neurons</th>\n",
              "      <th>optimizer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11/15/20-170636</td>\n",
              "      <td>11/15/20-170638</td>\n",
              "      <td>2.031990</td>\n",
              "      <td>40</td>\n",
              "      <td>10.851995</td>\n",
              "      <td>2.304056</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>rmsprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11/15/20-170638</td>\n",
              "      <td>11/15/20-170639</td>\n",
              "      <td>0.910489</td>\n",
              "      <td>20</td>\n",
              "      <td>17.655525</td>\n",
              "      <td>3.030559</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11/15/20-170639</td>\n",
              "      <td>11/15/20-170652</td>\n",
              "      <td>13.136339</td>\n",
              "      <td>80</td>\n",
              "      <td>8.214505</td>\n",
              "      <td>1.890268</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>rmsprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11/15/20-170652</td>\n",
              "      <td>11/15/20-170700</td>\n",
              "      <td>7.283268</td>\n",
              "      <td>80</td>\n",
              "      <td>29.768623</td>\n",
              "      <td>3.840412</td>\n",
              "      <td>2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>80</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11/15/20-170700</td>\n",
              "      <td>11/15/20-170700</td>\n",
              "      <td>0.616128</td>\n",
              "      <td>10</td>\n",
              "      <td>273.657898</td>\n",
              "      <td>13.904839</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>rmsprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>11/15/20-170700</td>\n",
              "      <td>11/15/20-170704</td>\n",
              "      <td>4.040827</td>\n",
              "      <td>40</td>\n",
              "      <td>17.316519</td>\n",
              "      <td>3.006269</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>40</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>rmsprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>11/15/20-170705</td>\n",
              "      <td>11/15/20-170709</td>\n",
              "      <td>3.977280</td>\n",
              "      <td>80</td>\n",
              "      <td>9.745456</td>\n",
              "      <td>2.233942</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>11/15/20-170709</td>\n",
              "      <td>11/15/20-170711</td>\n",
              "      <td>2.302304</td>\n",
              "      <td>20</td>\n",
              "      <td>25.224480</td>\n",
              "      <td>3.394042</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>rmsprop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>11/15/20-170711</td>\n",
              "      <td>11/15/20-170712</td>\n",
              "      <td>0.850609</td>\n",
              "      <td>10</td>\n",
              "      <td>29.615744</td>\n",
              "      <td>3.953907</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11/15/20-170712</td>\n",
              "      <td>11/15/20-170713</td>\n",
              "      <td>0.831331</td>\n",
              "      <td>20</td>\n",
              "      <td>213.837860</td>\n",
              "      <td>12.137146</td>\n",
              "      <td>8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             start              end  ...  number_of_neurons  optimizer\n",
              "0  11/15/20-170636  11/15/20-170638  ...                 64    rmsprop\n",
              "1  11/15/20-170638  11/15/20-170639  ...                 16       Adam\n",
              "2  11/15/20-170639  11/15/20-170652  ...                 16    rmsprop\n",
              "3  11/15/20-170652  11/15/20-170700  ...                  8       Adam\n",
              "4  11/15/20-170700  11/15/20-170700  ...                 16    rmsprop\n",
              "5  11/15/20-170700  11/15/20-170704  ...                 16    rmsprop\n",
              "6  11/15/20-170705  11/15/20-170709  ...                 16       Adam\n",
              "7  11/15/20-170709  11/15/20-170711  ...                 16    rmsprop\n",
              "8  11/15/20-170711  11/15/20-170712  ...                  8       Adam\n",
              "9  11/15/20-170712  11/15/20-170713  ...                  8       Adam\n",
              "\n",
              "[10 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Alz0NFrh0SaH"
      },
      "source": [
        "The output on my local computer is (the results should differ on your machine since you \n",
        "consider ten other random parameter configurations)\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/DLR-SC/Hyperparameter_tutorial/master/img/talos_scan_output.png' \n",
        "width=1000px>\n",
        "\n",
        "There are several hyperparameter configurations with a mean average error (mae) in the range 2-3 \n",
        "(i.e. the average house pricing error is 2000-3000 dollar).\n",
        "Since the number of training samples is only 400, the results of the mean average error \n",
        "have a high variance and should not be overestimated. Nevertheless, we already obtain a certain \n",
        "understanding of a sensible size of some of the hyperparameters (e.g. 10 epochs is certainly not\n",
        " enough since 'mae' becomes large then).\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "_tmty_UX0SaI"
      },
      "source": [
        "You already noticed that your results differ from mine. This is due to the usage of a 'random search'\n",
        "strategy in Talos. More information on the search strategy are given \n",
        "in the summary details using <code>scan_object.details</code>.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "CQRu4Pus0SaJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b909d182-56a3-496d-cf48-d093b6aa9e58"
      },
      "source": [
        "# access the summary details\n",
        "scan_object.details\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "experiment_name        find_optimal_params\n",
              "random_method             uniform_mersenne\n",
              "reduction_method                      None\n",
              "reduction_interval                      50\n",
              "reduction_window                        20\n",
              "reduction_threshold                    0.2\n",
              "reduction_metric                   val_acc\n",
              "complete_time               11/15/20/17:07\n",
              "x_shape                          (404, 13)\n",
              "y_shape                             (404,)\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Z1gXtp9d0SaO"
      },
      "source": [
        "From the 768 possible hyperparameter configurations Talos considers a random subset\n",
        "of ten configurations (due to <code>round_limit=10</code>). This random subset \n",
        "is chosen with a 'Mersenne Twister' pseudorandom number generator. Other possible\n",
        "random choices in Talos are, for instance, 'Halton' or 'Sobol' quasi Monte Carlo sequences.\n",
        "\n",
        "Note: If there is no parameter such as  <code> round_limit=10</code> or\n",
        "<code> fraction_limit = 0.1</code> the default optimization strategy \n",
        "is called 'grid search'. This means that all hyperparameter permutations in \n",
        "a given dictionary are processed. In most cases, this is not recommended\n",
        "for anything but very small permutation spaces. \n",
        "Therefore, better use a 'random search' routine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4QPj4UV0SaP"
      },
      "source": [
        "In addition to statistics and meta-data related with the Scan, the used data (x and y) \n",
        "together with the saved model and model weights for each hyperparameter permutation is stored in the Scan object. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "lb6F3yMa0SaQ"
      },
      "source": [
        "# accessing the saved models which returns a list of models\n",
        "# scan_object.saved_models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY6_FMvh0SaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af8de213-49a3-4d0a-cae0-bd2b73affd78"
      },
      "source": [
        "# accessing the saved weights for models which returns a list of weights\n",
        "model_weights = scan_object.saved_weights\n",
        "\n",
        "# weights of first model \n",
        "model_weights[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 4.57425296e-01, -5.16298115e-01,  2.21267313e-01,\n",
              "          8.37021507e-03, -7.20098540e-02, -1.22040488e-01,\n",
              "         -6.22698665e-01,  8.69533196e-02, -6.62737727e-01,\n",
              "         -4.58013058e-01, -1.41301215e-01, -3.25627774e-01,\n",
              "         -7.33099401e-01, -6.76608503e-01, -4.13446799e-02,\n",
              "         -3.43108475e-01, -2.02433050e-01, -3.42689276e-01,\n",
              "         -6.30362272e-01, -2.90668547e-01, -1.36713848e-01,\n",
              "         -2.66653478e-01, -2.71783292e-01, -6.15671039e-01,\n",
              "         -3.39812130e-01, -5.70169568e-01, -5.88431358e-01,\n",
              "          1.17279686e-01, -3.16596836e-01,  4.40082192e-01,\n",
              "         -1.83921069e-01, -2.97616065e-01, -2.11481497e-01,\n",
              "         -2.31853187e-01, -8.88207927e-03, -8.71220231e-02,\n",
              "         -3.73570502e-01, -3.86545479e-01, -3.16159904e-01,\n",
              "         -2.83033311e-01,  2.30595723e-01,  8.29937905e-02,\n",
              "          2.31925882e-02, -4.34886932e-01, -7.05738008e-01,\n",
              "          2.24851251e-01,  4.53285009e-01,  1.58026546e-01,\n",
              "         -3.36840600e-01,  9.91786122e-02, -6.53158963e-01,\n",
              "          3.68530989e-01,  6.17764443e-02,  2.89678834e-02,\n",
              "          2.22828835e-01, -4.21541244e-01,  1.03438430e-01,\n",
              "         -4.60909992e-01, -4.02023822e-01, -3.98609847e-01,\n",
              "          1.29953206e-01,  3.45751703e-01, -1.67917058e-01,\n",
              "         -5.33133090e-01],\n",
              "        [-7.24175200e-02,  1.10014388e-02,  5.60456216e-02,\n",
              "         -1.01499083e-02, -7.10983932e-01, -4.26680565e-01,\n",
              "          3.91747281e-02, -7.22040892e-01,  1.21775217e-01,\n",
              "          1.30061209e-01, -5.93291342e-01, -1.39074698e-01,\n",
              "          1.89803764e-01, -2.02569664e-01, -1.60958961e-01,\n",
              "          2.44217545e-01,  1.09674320e-01,  2.19385758e-01,\n",
              "         -1.03075020e-01,  1.07370719e-01,  1.23865688e-02,\n",
              "         -2.54490197e-01, -2.85815686e-01,  2.71634329e-02,\n",
              "         -3.84656750e-02, -2.00811461e-01, -2.08872467e-01,\n",
              "          1.42279491e-01, -9.75722969e-02, -5.70142902e-02,\n",
              "         -3.66749130e-02, -5.32904029e-01, -1.56884238e-01,\n",
              "          7.69509748e-02, -4.38172460e-01, -2.87963629e-01,\n",
              "         -3.76281515e-02, -1.06666133e-01,  2.25806996e-01,\n",
              "         -5.76078296e-01,  1.25931092e-02, -6.06511757e-02,\n",
              "          1.97068140e-01, -3.89233232e-01, -1.62543103e-01,\n",
              "         -1.53515127e-03, -2.12506694e-03,  3.03631693e-01,\n",
              "         -2.02274099e-01, -2.08658114e-01, -1.48462772e-01,\n",
              "          3.78391296e-01, -5.01449168e-01, -3.66230100e-01,\n",
              "         -3.26557547e-01,  4.60051708e-02,  2.22579628e-01,\n",
              "         -1.10871270e-02, -4.80547071e-01,  2.41699368e-01,\n",
              "          2.41930440e-01,  1.57509699e-01, -1.76942781e-01,\n",
              "          1.18972294e-01],\n",
              "        [ 1.57040834e-01,  2.55916622e-02, -9.36414395e-03,\n",
              "         -2.01899514e-01,  6.12467468e-01,  8.94976258e-02,\n",
              "          5.78907691e-02,  1.14115819e-01, -2.07006320e-01,\n",
              "         -7.80598521e-02,  4.68381435e-01, -1.28676236e-01,\n",
              "         -1.65956706e-01,  3.79793271e-02, -1.34903833e-01,\n",
              "         -3.32818002e-01,  1.29158005e-01, -4.15470153e-01,\n",
              "         -2.87389368e-01, -3.72426540e-01,  2.06069559e-01,\n",
              "         -3.41851334e-03, -6.24035299e-02, -3.70866030e-01,\n",
              "         -1.43500268e-01,  2.68499315e-01, -4.42289114e-02,\n",
              "          7.52107948e-02,  3.06738261e-02,  2.30264887e-01,\n",
              "         -7.02602342e-02,  3.76599044e-01, -4.61949497e-01,\n",
              "         -5.45678809e-02,  4.98124510e-01,  4.60060000e-01,\n",
              "         -3.87810022e-01,  3.05980235e-01, -7.44124427e-02,\n",
              "          1.66414067e-01,  9.39888433e-02, -1.36870205e-01,\n",
              "          4.89034414e-01, -1.36260670e-02, -7.60650411e-02,\n",
              "          1.42612621e-01,  1.49065098e-02,  4.01496351e-01,\n",
              "          1.35579541e-01,  2.85929471e-01, -4.01394606e-01,\n",
              "          1.26303837e-01,  5.70411325e-01,  1.81622729e-01,\n",
              "         -2.20633019e-03,  4.54913855e-01, -9.59080979e-02,\n",
              "         -3.78707677e-01, -1.99003220e-01,  6.08672202e-02,\n",
              "          2.63508618e-01, -1.87080234e-01, -9.49129835e-02,\n",
              "          7.23301545e-02],\n",
              "        [-2.92913187e-02,  1.88558787e-01, -5.75150177e-02,\n",
              "         -3.69721390e-02,  3.46361220e-01,  1.26518379e-03,\n",
              "         -8.94943476e-02, -1.92671373e-01, -1.07037440e-01,\n",
              "         -3.42643946e-01,  1.25366449e-01,  2.57191099e-02,\n",
              "         -2.72922337e-01, -5.60356796e-01,  2.89997905e-02,\n",
              "          1.15473352e-01, -2.07801163e-02,  3.05058956e-01,\n",
              "         -4.67468679e-01, -3.70480597e-01,  2.75836825e-01,\n",
              "         -3.74439627e-01,  3.14548343e-01,  1.55978784e-01,\n",
              "          2.40059629e-01,  3.25734347e-01,  3.66085798e-01,\n",
              "          2.28834506e-02, -2.14386418e-01, -2.51072180e-02,\n",
              "         -2.03936305e-02,  3.42310816e-01, -1.29556865e-01,\n",
              "          8.04990008e-02,  4.53969300e-01, -1.22020647e-01,\n",
              "         -2.24171877e-01,  3.15431684e-01, -1.84951693e-01,\n",
              "          4.44696248e-01, -3.09981983e-02, -1.35710672e-01,\n",
              "          3.03781092e-01, -5.87475538e-01, -4.66026783e-01,\n",
              "          1.31947577e-01, -1.15000643e-01, -1.54852346e-02,\n",
              "          3.02469581e-01,  2.00050816e-01, -2.02743322e-01,\n",
              "          1.14293918e-01,  2.18124256e-01,  2.16933981e-01,\n",
              "          2.61143684e-01,  2.74751097e-01,  4.77522582e-01,\n",
              "          1.08889200e-01, -6.94334745e-01, -3.74930263e-01,\n",
              "          1.15381345e-01, -1.00448489e-01, -2.92738199e-01,\n",
              "         -1.77124113e-01],\n",
              "        [ 2.32792899e-01, -3.39857340e-01,  8.06746334e-02,\n",
              "         -2.09166408e-01, -1.44934624e-01,  5.37192896e-02,\n",
              "         -3.66574675e-01, -2.86359582e-02, -2.98763335e-01,\n",
              "         -3.11547905e-01, -9.66758355e-02, -3.98514032e-01,\n",
              "         -2.70825803e-01, -1.90719545e-01,  9.84399319e-02,\n",
              "         -3.31372142e-01, -1.52153417e-01, -1.42056659e-01,\n",
              "         -4.68044043e-01, -3.66660923e-01, -2.11701877e-02,\n",
              "          2.22887039e-01, -2.13863447e-01, -5.01348615e-01,\n",
              "          2.23204996e-02, -3.09639782e-01, -4.91171062e-01,\n",
              "          3.85221601e-01,  2.77475536e-01,  2.55841106e-01,\n",
              "         -8.24836418e-02,  1.60234571e-01, -5.13463616e-01,\n",
              "         -1.21291243e-01,  1.68140411e-01,  2.70050704e-01,\n",
              "         -2.68925756e-01,  2.11827710e-01,  3.05091478e-02,\n",
              "         -6.68291524e-02,  3.08564752e-01, -8.20319504e-02,\n",
              "          9.17962492e-02, -1.09070405e-01, -1.37030900e-01,\n",
              "         -6.95700347e-02,  4.35201771e-04,  4.39927988e-02,\n",
              "         -2.28334561e-01, -3.41908216e-01, -3.61871541e-01,\n",
              "          6.15322664e-02, -7.57243717e-03,  1.89372554e-01,\n",
              "          1.75055683e-01,  3.75322551e-02, -1.99468479e-01,\n",
              "         -3.24536800e-01,  4.01037484e-02, -3.52593541e-01,\n",
              "          1.62441224e-01, -5.51004671e-02, -2.25013569e-01,\n",
              "          1.20752361e-02],\n",
              "        [ 4.07115072e-02,  2.40175352e-01, -1.73958868e-01,\n",
              "         -1.31425589e-01, -3.93325746e-01,  1.09277174e-01,\n",
              "          4.45119619e-01, -6.90631211e-01,  3.97269696e-01,\n",
              "          6.50432527e-01, -1.78863660e-01,  3.87017637e-01,\n",
              "          5.35150349e-01,  2.50304807e-02,  6.54918075e-01,\n",
              "          4.96003509e-01,  1.74388245e-01,  2.58707255e-01,\n",
              "          6.74142838e-02,  2.36515045e-01,  5.72087884e-01,\n",
              "         -5.51980495e-01,  6.67763770e-01,  5.62101938e-02,\n",
              "          3.08956206e-01, -1.07909456e-01,  4.92026150e-01,\n",
              "          4.87248078e-02,  4.16155308e-01,  7.32982457e-02,\n",
              "         -8.13448206e-02, -4.88416344e-01, -8.10652003e-02,\n",
              "         -2.67647713e-01,  2.92324781e-01, -2.55046219e-01,\n",
              "          6.06532395e-01, -5.39944805e-02,  7.21061766e-01,\n",
              "         -2.31101453e-01,  5.63462898e-02,  8.57423991e-02,\n",
              "          4.83370483e-01, -3.07783961e-01,  2.12629139e-01,\n",
              "         -6.26364201e-02,  1.66505530e-01,  5.54493487e-01,\n",
              "         -1.95031330e-01, -7.99348652e-02,  2.12996230e-01,\n",
              "         -1.66714862e-01, -4.67313766e-01,  8.39900523e-02,\n",
              "          2.03294069e-01,  3.30602050e-01,  6.42739415e-01,\n",
              "          3.51762384e-01, -6.60605907e-01,  1.04502209e-01,\n",
              "          3.50929499e-01,  1.86735727e-02,  3.71834219e-01,\n",
              "          2.25492403e-01],\n",
              "        [ 1.83292225e-01, -2.23385528e-01, -1.08717009e-01,\n",
              "         -8.35743099e-02,  2.89221674e-01,  2.08741557e-02,\n",
              "          4.79126871e-02,  2.56388277e-01, -5.52415811e-02,\n",
              "          2.87028234e-02,  4.91159856e-01, -8.94026980e-02,\n",
              "          3.20203714e-02,  2.57494021e-02,  4.17131037e-02,\n",
              "         -3.87075335e-01, -1.61995098e-01, -7.18524605e-02,\n",
              "         -3.34101021e-01, -2.89416164e-01, -3.16117853e-01,\n",
              "          3.16690594e-01,  3.57108116e-01, -3.71872008e-01,\n",
              "          3.49480838e-01, -1.93597879e-02,  3.22759837e-01,\n",
              "          1.96664914e-01, -1.13984592e-01,  1.64304584e-01,\n",
              "          2.17997096e-02,  1.93104491e-01, -2.44630247e-01,\n",
              "         -1.06924579e-01,  2.11876065e-01,  4.57754850e-01,\n",
              "          3.32942642e-02,  1.83579221e-01,  4.38364930e-02,\n",
              "          2.86604643e-01,  7.60598779e-02,  3.16776454e-01,\n",
              "          6.10882044e-02,  4.27932948e-01,  1.48471892e-01,\n",
              "         -1.62804991e-01,  2.23125309e-01,  6.09621629e-02,\n",
              "          5.75037338e-02,  1.94023680e-02, -2.57971972e-01,\n",
              "         -3.14893201e-02,  2.79392213e-01,  1.66801110e-01,\n",
              "          7.84991682e-02, -3.59444261e-01,  3.68241332e-02,\n",
              "         -4.11751121e-01, -2.50895202e-01, -3.15521926e-01,\n",
              "         -2.41912361e-02,  4.02339771e-02,  2.02055693e-01,\n",
              "         -2.86878496e-01],\n",
              "        [ 1.47097081e-01, -1.47659615e-01,  3.44681948e-01,\n",
              "          8.58434290e-02, -5.92528760e-01, -5.12174293e-02,\n",
              "         -1.31727591e-01, -5.60356081e-02, -2.49411792e-01,\n",
              "          1.74042005e-02, -5.95553815e-01,  9.29073021e-02,\n",
              "         -2.89366007e-01,  1.28304034e-01,  1.52075673e-02,\n",
              "          6.71208575e-02, -3.15706074e-01,  1.60337368e-03,\n",
              "         -4.41012122e-02, -2.47650407e-02, -5.10018058e-02,\n",
              "         -3.97542059e-01, -5.42718649e-01,  4.08223681e-02,\n",
              "          4.89889309e-02, -1.99253447e-02,  2.63300873e-02,\n",
              "          5.05790021e-03, -5.94533861e-01,  4.83706482e-02,\n",
              "          1.70188814e-01, -3.67344379e-01,  3.10213715e-02,\n",
              "          1.51850238e-01, -5.71793616e-02, -6.44053638e-01,\n",
              "          8.26985911e-02, -1.22567542e-01, -1.43937320e-01,\n",
              "         -4.42344189e-01, -1.14604607e-01, -3.56662363e-01,\n",
              "         -4.03525323e-01, -1.19119562e-01, -2.50449836e-01,\n",
              "         -2.76280612e-01, -1.72294483e-01, -3.06392819e-01,\n",
              "         -2.80529022e-01,  1.54627606e-01, -8.45934153e-02,\n",
              "          7.65256807e-02, -2.92993277e-01,  9.41548645e-02,\n",
              "         -8.15058872e-02,  1.36813417e-03,  1.60960272e-01,\n",
              "         -2.81390339e-01,  1.77001581e-01, -1.93383157e-01,\n",
              "         -2.39800930e-01,  8.66325870e-02, -3.18985619e-02,\n",
              "          5.86335398e-02],\n",
              "        [ 3.69680002e-02,  2.76588082e-01, -7.33563974e-02,\n",
              "         -1.28294826e-01,  2.99997121e-01,  2.75177389e-01,\n",
              "         -2.10885525e-01,  4.24384177e-01, -2.61949837e-01,\n",
              "         -1.56269610e-01,  4.00636822e-01, -1.66998785e-02,\n",
              "         -3.23821932e-01, -3.33261400e-01, -6.39879629e-02,\n",
              "         -5.63093603e-01, -1.15728885e-01, -9.46237370e-02,\n",
              "          1.35820284e-01, -5.02348602e-01, -1.25520185e-01,\n",
              "         -4.85058963e-01, -1.13395363e-01, -4.20282632e-01,\n",
              "         -1.03768416e-01,  5.92913777e-02, -3.45991611e-01,\n",
              "          1.84471443e-01,  3.82731616e-01,  7.97324479e-02,\n",
              "         -1.67314917e-01,  2.54071355e-01, -2.71955401e-01,\n",
              "         -2.23872021e-01,  4.75962758e-01,  2.82130957e-01,\n",
              "         -9.89091489e-03,  1.34092540e-01,  1.78959027e-01,\n",
              "          4.53985423e-01,  8.21923241e-02, -7.62835294e-02,\n",
              "          4.35077697e-01, -2.87220299e-01, -4.47032988e-01,\n",
              "          5.44131957e-02,  1.08957157e-01,  2.04601660e-02,\n",
              "         -4.10545804e-02,  2.72751868e-01, -2.95674782e-02,\n",
              "          3.49063784e-01,  4.20792729e-01,  3.69866006e-02,\n",
              "         -5.48579246e-02,  2.29684830e-01,  4.29946870e-01,\n",
              "         -3.60998884e-02,  2.63381690e-01, -3.42522562e-01,\n",
              "          3.99215013e-01,  2.22556189e-01, -1.15258388e-01,\n",
              "         -3.76183301e-01],\n",
              "        [ 1.77155018e-01,  1.11712061e-01,  5.45679927e-02,\n",
              "         -1.97079033e-01,  5.17822206e-02, -4.41224463e-02,\n",
              "         -5.67015052e-01,  4.19444650e-01, -4.04153705e-01,\n",
              "         -3.24363530e-01,  2.14469969e-01, -4.43270922e-01,\n",
              "         -1.68504044e-01, -4.95971292e-01, -2.98828870e-01,\n",
              "         -3.15821797e-01, -6.61236942e-02, -2.51083106e-01,\n",
              "         -1.75369039e-01, -5.99314235e-02, -2.58664906e-01,\n",
              "         -5.07145941e-01, -4.49510545e-01, -2.83385605e-01,\n",
              "         -4.55793649e-01, -7.77756795e-02, -4.13465738e-01,\n",
              "          3.92750204e-02,  1.62156209e-01,  1.49643093e-01,\n",
              "         -2.72357523e-01,  1.78800672e-02, -2.27652937e-01,\n",
              "         -3.64468084e-04,  3.07133168e-01,  4.69647020e-01,\n",
              "         -4.59615171e-01,  3.44505906e-01,  2.53810883e-01,\n",
              "          2.04079315e-01, -2.09587831e-02,  8.12797025e-02,\n",
              "          1.64262235e-01, -7.85994008e-02, -4.92344648e-01,\n",
              "          1.81470737e-02,  2.74327755e-01,  4.22441633e-03,\n",
              "          3.96868616e-01,  3.98986518e-01, -5.60988128e-01,\n",
              "         -4.43855971e-02,  3.41742396e-01,  4.29515272e-01,\n",
              "         -8.07991922e-02,  2.25289017e-01,  4.11934614e-01,\n",
              "         -4.91937816e-01,  2.23183051e-01, -3.49896878e-01,\n",
              "         -2.66311932e-02,  2.30228409e-01, -1.41656548e-01,\n",
              "         -3.03098083e-01],\n",
              "        [-6.53531775e-02,  2.20030785e-01, -8.71344954e-02,\n",
              "         -9.73882675e-02,  3.82910609e-01,  4.64362293e-01,\n",
              "         -2.35602543e-01,  4.37789142e-01, -5.37296608e-02,\n",
              "         -4.81292456e-01,  3.74853700e-01, -4.55186814e-01,\n",
              "         -3.67660105e-01, -5.69617629e-01, -2.30633855e-01,\n",
              "         -2.20712885e-01, -4.73533683e-02,  1.61705390e-01,\n",
              "          9.49296504e-02, -6.82566175e-03, -3.97034645e-01,\n",
              "          1.32107139e-02, -3.81132931e-01,  1.48478970e-02,\n",
              "         -3.98940057e-01,  4.17559117e-01,  1.17615514e-01,\n",
              "          1.07242577e-01, -4.76549059e-01, -6.42438829e-02,\n",
              "          6.87146559e-03,  3.57228190e-01,  2.81627625e-01,\n",
              "         -2.44533256e-01, -3.83105189e-01,  4.76387113e-01,\n",
              "         -5.59809506e-01, -3.44129115e-01, -3.86878878e-01,\n",
              "         -2.64589846e-01,  6.03515208e-02, -3.38835835e-01,\n",
              "         -3.42064828e-01, -9.21788216e-02, -4.20869648e-01,\n",
              "          2.89094061e-01,  7.99629614e-02, -4.32775766e-02,\n",
              "          1.49011031e-01,  1.35064527e-01,  9.97261703e-02,\n",
              "         -1.62747517e-01,  4.50968474e-01, -1.45269349e-01,\n",
              "          4.59864706e-01, -1.95825044e-02,  6.66689500e-02,\n",
              "         -2.04422295e-01,  2.95799747e-02,  3.75094786e-02,\n",
              "         -1.40939087e-01,  9.70735122e-03, -1.69047341e-01,\n",
              "          3.98438983e-02],\n",
              "        [-5.02783209e-02,  6.40315711e-01,  8.38889554e-02,\n",
              "         -1.44867254e-02, -6.93769082e-02,  3.41173410e-01,\n",
              "          2.90271789e-01, -2.38822624e-01,  3.23604137e-01,\n",
              "          2.32267916e-01,  3.33603948e-01,  3.41956705e-01,\n",
              "          1.44882321e-01,  3.88670534e-01,  2.25882158e-01,\n",
              "          1.33305386e-01, -1.41399220e-01,  9.32433754e-02,\n",
              "          1.00198463e-01,  1.87830374e-01,  4.05810833e-01,\n",
              "         -1.64889380e-01,  4.84253228e-01,  2.67814606e-01,\n",
              "          5.70337713e-01,  3.28400254e-01,  4.58438337e-01,\n",
              "         -1.15069106e-01,  1.52295724e-01,  1.50065385e-02,\n",
              "          1.00955792e-01, -1.96150333e-01, -3.80366817e-02,\n",
              "          9.23317820e-02,  2.41766527e-01,  2.27423795e-02,\n",
              "          5.07629395e-01,  5.31115085e-02,  1.44200712e-01,\n",
              "         -9.43995938e-02, -6.30257726e-02,  4.58367839e-02,\n",
              "         -1.31657943e-01, -1.49424985e-01,  2.50912458e-01,\n",
              "          1.01095796e-01, -9.79800224e-02, -1.73925627e-02,\n",
              "         -1.43791735e-01,  1.78440977e-02,  4.62043405e-01,\n",
              "         -1.44296940e-02, -4.54646535e-02,  3.40243280e-01,\n",
              "          1.61412477e-01,  1.24406107e-01,  9.95670408e-02,\n",
              "          5.39226949e-01, -1.98938131e-01,  4.29584473e-01,\n",
              "         -1.30273998e-01,  3.44742090e-01,  3.44510347e-01,\n",
              "          1.59074306e-01],\n",
              "        [ 3.80192161e-01, -6.72990084e-01, -1.95079800e-02,\n",
              "         -2.56531894e-01, -1.98479425e-02, -7.44387984e-01,\n",
              "          8.67106915e-02,  1.00267611e-01, -1.52836889e-01,\n",
              "         -4.76238281e-01, -2.02321246e-01, -1.87592164e-01,\n",
              "         -8.07019975e-03,  1.42238826e-01, -4.29667592e-01,\n",
              "          1.00122064e-01,  9.94656980e-02, -1.07798167e-01,\n",
              "         -1.54497130e-02, -5.07468097e-02, -3.74294877e-01,\n",
              "          1.30397886e-01, -1.32126927e-01, -2.19721764e-01,\n",
              "         -2.76165068e-01, -1.13936357e-01, -4.33726221e-01,\n",
              "          4.89561319e-01, -7.77605236e-01,  4.71463650e-01,\n",
              "         -2.30625913e-01, -3.13961618e-02, -4.44750637e-02,\n",
              "         -2.86263853e-01, -8.47235382e-01, -3.29032272e-01,\n",
              "         -4.43925649e-01, -1.75718591e-01, -7.03970075e-01,\n",
              "         -2.87152022e-01,  2.93071777e-01, -4.28287238e-01,\n",
              "         -4.24443096e-01, -1.15497515e-01, -4.53529507e-02,\n",
              "         -5.77478886e-01,  5.41256964e-01, -4.94541794e-01,\n",
              "         -5.74599147e-01, -7.57457376e-01, -1.46171734e-01,\n",
              "          3.59529138e-01, -1.66139528e-01, -2.75721788e-01,\n",
              "         -5.38604498e-01, -4.27283078e-01, -3.14555198e-01,\n",
              "          1.59570873e-01, -9.19878036e-02, -3.32372338e-01,\n",
              "         -6.64137006e-01,  2.80932039e-01, -2.51414001e-01,\n",
              "         -5.25750779e-02]], dtype=float32),\n",
              " array([-0.15503508,  0.5543476 , -0.17792596, -0.14276575,  0.62217665,\n",
              "         0.4276162 ,  0.5406279 ,  0.6147308 ,  0.5385351 ,  0.4423299 ,\n",
              "         0.55143803,  0.5091694 ,  0.52148   ,  0.57130134,  0.3593324 ,\n",
              "         0.52259135, -0.03197912,  0.5342725 ,  0.59396964,  0.5108385 ,\n",
              "         0.4365911 ,  0.35868365,  0.51996285,  0.51933587,  0.53776217,\n",
              "         0.5597561 ,  0.54744655, -0.18013586,  0.47217947, -0.1927356 ,\n",
              "        -0.13694268,  0.61365604,  0.47656187, -0.18244475,  0.41516265,\n",
              "         0.55544096,  0.44594374,  0.22986197,  0.4466456 ,  0.516666  ,\n",
              "        -0.15952429,  0.2243235 ,  0.45307177,  0.34008968,  0.55572796,\n",
              "        -0.05721688, -0.20249957,  0.13706173,  0.14509453,  0.06396545,\n",
              "         0.5208806 , -0.13278846,  0.5451907 ,  0.25567743,  0.08161381,\n",
              "         0.34092176,  0.34740868,  0.5064384 ,  0.44573617,  0.5191217 ,\n",
              "         0.11975889, -0.10620301,  0.344403  ,  0.39732364], dtype=float32),\n",
              " array([[-0.29762048],\n",
              "        [ 0.45101482],\n",
              "        [-0.29264897],\n",
              "        [-0.25185826],\n",
              "        [ 0.44938698],\n",
              "        [ 0.48931277],\n",
              "        [ 0.62698793],\n",
              "        [ 0.6177974 ],\n",
              "        [ 0.61898905],\n",
              "        [ 0.38287574],\n",
              "        [ 0.62751234],\n",
              "        [ 0.38186014],\n",
              "        [ 0.62654215],\n",
              "        [ 0.48775148],\n",
              "        [ 0.3017117 ],\n",
              "        [ 0.57201236],\n",
              "        [ 0.30348328],\n",
              "        [ 0.5369037 ],\n",
              "        [ 0.44415253],\n",
              "        [ 0.29470792],\n",
              "        [ 0.31446114],\n",
              "        [ 0.47505   ],\n",
              "        [ 0.49050462],\n",
              "        [ 0.516364  ],\n",
              "        [ 0.39589423],\n",
              "        [ 0.6975545 ],\n",
              "        [ 0.48046795],\n",
              "        [-0.35959142],\n",
              "        [ 0.7860091 ],\n",
              "        [-0.39547968],\n",
              "        [-0.24616759],\n",
              "        [ 0.4166954 ],\n",
              "        [ 0.29044145],\n",
              "        [-0.2335696 ],\n",
              "        [ 0.7319746 ],\n",
              "        [ 0.39671385],\n",
              "        [ 0.47984812],\n",
              "        [ 0.240189  ],\n",
              "        [ 0.48613638],\n",
              "        [ 0.63869405],\n",
              "        [-0.34670416],\n",
              "        [ 0.3119045 ],\n",
              "        [ 0.61409503],\n",
              "        [ 0.4475901 ],\n",
              "        [ 0.702211  ],\n",
              "        [ 0.25567794],\n",
              "        [-0.3918871 ],\n",
              "        [ 0.469815  ],\n",
              "        [ 0.28371206],\n",
              "        [ 0.34039956],\n",
              "        [ 0.61343473],\n",
              "        [-0.21831621],\n",
              "        [ 0.6069335 ],\n",
              "        [ 0.2569081 ],\n",
              "        [ 0.26605988],\n",
              "        [ 0.47247845],\n",
              "        [ 0.70132494],\n",
              "        [ 0.46486548],\n",
              "        [ 0.7956985 ],\n",
              "        [ 0.57743424],\n",
              "        [ 0.4611317 ],\n",
              "        [-0.21215057],\n",
              "        [ 0.30384666],\n",
              "        [ 0.27495083]], dtype=float32),\n",
              " array([0.53483784], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz3UHlhJ0SaZ"
      },
      "source": [
        "The Scan object can be further used, and is required, as input for Predict(), Evaluate(), and Deploy(). \n",
        "More about this in the corresponding sections below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-xSwPUN0Saa"
      },
      "source": [
        "### Analysing the Scan results with <code>Reporting()</code> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFlHbn2M0Sab"
      },
      "source": [
        "In the Scan process, the results are stored round-by-round in the corresponding experiment log which is a .csv file stored in the \n",
        "output directory (which is './find_optimal_params' our case). The Reporting() \n",
        "accepts as its source either a file name, or the Scan object. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBDBp2Va0Sac"
      },
      "source": [
        "# use Scan object as input\n",
        "analyze_object = talos.Analyze(scan_object)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "gTpMC42h0Sah",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "888e47e5-f4b4-4a27-ac0d-8cf0b7fc2d6c"
      },
      "source": [
        "# get the number of rounds in the Scan\n",
        "analyze_object.rounds()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cRdJ8N_I0Sam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5888b95d-a833-4348-96ec-4da1bf24fd1c"
      },
      "source": [
        "# get the lowest result for any metric (if lower is better)\n",
        "analyze_object.low('mae')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.8902676105499268"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "0wcW4VRO0Sar"
      },
      "source": [
        "Next, we want to know the parameters of our best n=3 parameter runs. \n",
        "For this purpose we use <code> best_params</code>. It is alluring to consider the best \n",
        "result only (i.e. n=1 in the following cell) but keep in mind that due to the high\n",
        "variance in the result, a sequence of more models should be considered.\n",
        "\n",
        "The signature of <code> best_params()</code> is the following:\n",
        "* The first argument (here 'mae') is the metric that is considered.\n",
        "* The second argument is a list of metrics / loss functions that is not required here\n",
        "* The third argument gives the 'n' best results\n",
        "* Fourth argument: ascending | bool | Set to True when `metric` is to be minimized eg. loss or mae"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YJxYV6Dl0Sas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c44de1f-f99f-41a4-8558-4c980fc903f5"
      },
      "source": [
        "# get the best n=3 paramaters\n",
        "analyze_object.best_params('mae', ['loss'], n=3, ascending=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['rmsprop', 80, '11/15/20-170652', '11/15/20-170639', 80, nan, 16,\n",
              "        1, 13.136338949203491, 1, 0],\n",
              "       ['Adam', 80, '11/15/20-170709', '11/15/20-170705', 80, nan, 16, 1,\n",
              "        3.9772801399230957, 4, 1],\n",
              "       ['rmsprop', 40, '11/15/20-170638', '11/15/20-170636', 40, nan, 64,\n",
              "        1, 2.031989574432373, 8, 2]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "agb6i5oD0Sax"
      },
      "source": [
        "It is very important to determine which of your hyperparameters has the largest impact on \n",
        "your performance metric. These are the parameters that should be further investigated. \n",
        "\n",
        "One solution to achieve this is to compute the linear correlation between your performance metric\n",
        "'mae' and your hyperparamters. The correlation coefficient is +1 in the case of a perfect direct\n",
        "(increasing) linear relationship, -1 in the case of a perfect decreasing (inverse) linear \n",
        "relationship and some values in (-1, 1) otherwise (indicating the degree of linear dependance\n",
        "between the variables).\n",
        "\n",
        "We employ <code> correlate()</code> for computing the correlation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "eELdKefW0Say",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38160ec1-3554-4e2a-9452-3b9ff91cfbcf"
      },
      "source": [
        "# get correlation for hyperparameters against a performance metric such as 'mae' (we exclude 'loss' since \n",
        "# this is not a hyperparameter)\n",
        "analyze_object.correlate('mae', ['loss', 'round_epochs'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "duration            -0.441278\n",
              "batch_size           0.557118\n",
              "dropout_value        0.631923\n",
              "epoch_number        -0.514499\n",
              "number_of_layers    -0.372288\n",
              "number_of_neurons   -0.262926\n",
              "Name: mae, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "39cCaGzh0Sa6"
      },
      "source": [
        "Since you have only then different hyperparameter runs, the output is almost random. However, in practice \n",
        "with hundreds or thousand of different configurations the result is much less stochastic noise in this output.\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/DLR-SC/Hyperparameter_tutorial/master/img/talos_correlate.png' \n",
        "width=240px>\n",
        "\n",
        "In my special case, 'epoch_number' and 'number_of_neurons' have the strongest inverse effect on 'mae'\n",
        "(i.e. 'more epochs tend to lead to a lower mean average error'). The 'batch_size' seems to be less important. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL1G1O7d0Sa7"
      },
      "source": [
        "You can also plot a heatmap of this correlation using <code> plot_corr()</code>:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2ktVnpKO0Sa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e75c7ecb-861f-426b-f539-ddf908bb8b12"
      },
      "source": [
        "# heatmap correlation\n",
        "analyze_object.plot_corr('mae', ['loss', 'round_epochs'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "findfont: Font family ['Verdana'] not found. Falling back to DejaVu Sans.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnIAAAJaCAYAAACr0arOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde1yVZb7//zfrwAJBBDRADp4gTZ3ARDxkaWgZVsZMR7Amtz4mT5nz6PAdO5jbxmnG1IY9maa7draVSSlrl9KkWeouRwUPDDLlpDAwiaIoS1AQFrDW+v3hj7UlRDxgcOfr+Xj0eLCu+7qu9bkXpe+u677v5eV2u90CAACA4ZjaugAAAABcHoIcAACAQRHkAAAADIogBwAAYFAEOQAAAIMiyAEAABiUpa0LAAAA157PesRd1fnHFuVe1fnbC1bkAAAADIogBwAAYFAEOQAAAIMiyAEAABgUQQ4AAMCgCHIAAAAGRZADAAAwKIIcAACAQRHkAAAADIogBwAAYFAEOQAAAIMiyAEAABgUQQ4AAMCgCHIAAAAGRZADAAAwKIIcAACAQRHkAAAADIogBwAAYFAEOQAAAIMiyAEAABgUQQ4AAMCgCHIAAAAGRZADAAAwKIIcAACAQRHkAAAADIogBwAAYFAEOQAAAIMiyP3/ysrKNH36dDmdzrYupVmZmZlasWJFW5cBAADaCYIcAACAQRHkrlHteeURAABcHEtbF3Ah5eXlev/995Wfny+bzaZRo0YpMTFRmZmZKikpkZeXl7755huFhITol7/8pSIjIyVJJSUlWrNmjYqLixUYGKjk5GTFxsZKkmpra7V+/Xrl5OTozJkzioiI0JNPPul5z127dmn9+vWqra3VqFGjNHbs2AvWmJmZqaNHj8pisSg3N1fBwcF67LHH1L17d0nS9OnTNXfuXIWEhEiSVq5cqcDAQN177706cOCA3n33Xd1222364osvZDKZlJKSIovForVr16qyslK33367kpKSPO9XX1+vt99++7zn3dzn1VBnSUmJLBaL8vLydP/992v48OGt9JsCAOCnpaqqSunp6dq/f7/8/f2VnJyshISEJv3eeOMNFRQUeF7X19crNDRUs2fPliTNnj1bp0+flsl0du2sZ8+emjlzZqvV2W6DnMvl0ptvvqm4uDhNmjRJ5eXl+tOf/qTQ0FBJUm5uriZNmqSJEydq8+bNWr58uebOnStJWrZsmYYNG6Ynn3xSBQUFWrZsmZ577jmFhobqo48+UklJiZ599lkFBASosLBQXl5envctKCjQv//7v6u0tFQLFizQgAED1LVr1wvWum/fPk2ePFmPPfaY1q1bp4yMDP3mN7+5qPM8deqU6uvr9Yc//EE7duzQe++9pxtuuEHPPfec7Ha7Xn31VQ0aNEhdunS54Hl7eXk1+3n169fPM/ZXv/qVJkyYoPr6+kv9lQAAcM3IyMiQ2WzW/PnzVVxcrKVLlyoiIkLh4eGN+s2YMaPR67S0NPXp06dR27Rp03TDDTdclTrb7dbqv/71L1VWVuquu+6SxWJRly5dNHz4cO3evVuS1K1bNw0cOFBms1mjR49WXV2dCgsLVVhYKIfDoTFjxshisahPnz668cYbtWvXLrlcLu3YsUMPPvigAgMDZTKZFB0dLavV6nnfu+66S97e3oqMjFRERIQOHz7cYq3R0dH62c9+JpPJpCFDhlzUmAZms1lJSUkym80aNGiQKisrlZiYKB8fH4WHhyssLEzFxcWe/s2dd0uflyT16tVLAwYMkMlkkre390XXCADAtcThcCgnJ0fjxo2Tj4+PYmJiFBsbq+zs7AuOKysrU35+voYMGfIjVdqOV+TsdrsqKir0zDPPeNpcLpdiYmIUHBysoKAgT7vJZFJgYKDKy8slyRPSGgQHB6uiokJVVVWqq6vzrG6dT0BAgOdnb29vORyOFmv94Zi6ujo5nU6ZzeYWx/r5+XlqbQiUF6qhufP28vJq9vM631gAAHB+paWlMplMnl1ASYqIiNDBgwcvOC4rK0sxMTHq3Llzo/YVK1bI7XYrMjJS9913n+eSqNbQboNcUFCQOnfurJdffrnJsczMTJ08edLz2uVyqby8XIGBgZLOXivmcrk8AclutyskJER+fn6yWq06ceJEq36IF+Lt7a3a2lrP61OnTnnqvBzNnbfJZGr28wIAABfP4XDI19e3UZuvr2+LiztZWVmNrmuXpIkTJyoqKkqStHnzZr3xxhuaM2eOOnTo0Cq1ttut1R49esjHx0eff/65amtr5XK5dOTIERUVFUmSvv/+e+Xk5MjpdGrLli2yWCzq2bOnevToIavVqk2bNsnpdOrAgQPKy8vToEGDZDKZNGzYMH344YeesPfPf/5TdXV1V+08IiMjtXv3brlcLn3zzTctpvmWXOi8L/R5AQCAi2Oz2VRdXd2oraamRjabrdkx+fn5OnXqlG666aZG7dHR0fL29pa3t7eSkpLk6+ur/Pz8Vqu13a7ImUwmTZs2TR999JHmzJmjuro6hYaG6t5775UkxcXFac+ePVq5cqWuu+46TZ482bOVOW3aNK1Zs0YbN25UYGCgJkyYoLCwMEnSfffdp08++USvvvqqHA6HIiMjm1yo2JoefPBBrVy5Uv/7v/+ruLg4xcXFXdF8LZ13c58XAAC4OCEhIXK5XCotLfU8daK4uLjJjQ7nysrKUlxcnHx8fH6sMiVJXm632/2jvmMryMzM1PHjxzVx4sS2LgUAAFyGz3pc2cJGS8YW5V7R+P/6r/+Sl5eXHnnkERUXF2vJkiV69tlnzxvmamtr9dxzz2nKlCmN7li12+06efKkunfvLrfbra1bt2rTpk2aM2eO/P39r6i+Bu12RQ4AAKCtpKSkaNWqVZo1a5b8/PyUmpqq8PBw5efna8mSJUpLS/P0zc3NVYcOHdS7d+9Gc9TU1Gj16tU6ceKErFarIiMj9cQTT7RaiJNYkbsoP3zYX4M777yzyUWNAACgZe19Rc4oDBnkAACAsRHkWke7vWsVAAAAF0aQAwAAMCiCHAAAgEER5AAAAAyKIAcAAGBQBDkAAACDIsgBAAAYFEEOAADAoAhyAAAABkWQAwAAMCiCHAAAgEER5AAAAAyKIAcAAGBQBDkAAACDIsgBAAAYFEEOAADAoCxtXQAAALj29E7u29Yl/CSwIgcAAGBQBDkAAACDIsgBAAAYFEEOAADAoAhyAAAABkWQAwAAMCiCHAAAgEER5AAAAAyKBwLjstRs+M+2LqHV+SRNbusSAAC4JKzIAQAAGBRBDgAAwKAIcgAAAAZFkAMAADAoghwAAIBBEeQAAAAMiiAHAABgUAQ5AAAAgyLIAQAAGBRBDgAAwKAIcgAAAAZFkAMAADAoghwAAIBBEeQAAAAMiiAHAABgUAQ5AAAAgyLIAQAAGBRBDgAAwKAIcgAAAAZFkAMAADAoghwAAIBBEeQAAAAMiiAHAABgUAQ5AAAAg7K0dQEAAADtTVVVldLT07V//375+/srOTlZCQkJTfplZmZqw4YNslqtnrYXX3xRXbp0kSQdOnRI6enpOnr0qMLCwvToo48qKiqq1eokyAEAAPxARkaGzGaz5s+fr+LiYi1dulQREREKDw9v0jc+Pl4TJ05s0l5fX6/ly5crMTFRI0aM0LZt27R8+XLNnTtXFkvrRDDDbq2uXLlS69ata+syfnQ7duzQa6+91tZlAADwk+VwOJSTk6Nx48bJx8dHMTExio2NVXZ29iXNc+DAATmdTo0aNUpWq1WJiYlyu9367rvvWq1Wwwa59igtLU1//etf27oMAABwBUpLS2UymRQaGuppi4iI0JEjR87bPy8vT88++6zmzZunr776ytNeUlKiiIgIeXl5NZqnpKSk1Wr9yW2tOp1Omc3mti4DAAAYlMPhkK+vb6M2X19fORyOJn3j4+N1yy23KCAgQIWFhXrrrbfk6+urhISEZuepqalptVoNE+QaLhYsLS1V//79Pen2wIEDevfdd3Xbbbdp8+bNuuGGG/TII4/o448/1t69eyVJAwcO1M9//nNZrVZP/xEjRujLL7+UzWbTvffeq8GDB0uSqqurlZGRoW+//Vbe3t4aPny47rzzTplMJmVmZur48eOeffCysjK99NJLWrx4sTIzM5Wfn6/CwkKtXbtWQ4cO1cMPP3zec1m9erW8vb11//33e9qWLVum66+/XqNHj9bGjRv117/+VadPn1ZQUJDuvfdeDRgwoMk8575/Q3hNS0vT4MGDNXz4cEnS9u3btWnTJp06dUo9evTQ+PHj1blz51b6rQAA8NNjs9lUXV3dqK2mpkY2m61J365du3p+jo6OVmJionJycpSQkCCbzdYktFVXV8vHx6fVajXE1mrDxYKDBw/WokWLNHDgQOXk5HiOnzp1SlVVVZo3b57Gjx+vDRs2qLCwUC+88IJeeOEFFRUVacOGDY36V1ZW6ve//70ee+wxvffeezp27Jiksxc31tTU6Le//a2eeuopZWVlaceOHS3WmJycrJiYGD388MNKS0trNsRJ0qBBg7Rnzx653W5J0pkzZ7R//37Fx8dLkq677jo9/fTTeu2113TXXXfp3XffVUVFxSV/brm5udq4caMmT56sBQsWKCYmRu+8884lzwMAwLUkJCRELpdLpaWlnrbi4uLz3ujwQ15eXp6/37t27arDhw97XkvSkSNHGoW/K2WIIFdYWOi5WNBsNmvgwIHq3r2757iXl5fuueceWa1WeXt7a9euXbrrrrvUsWNHdezYUXfffbeysrIazTlu3DhZrVb17t1bP/vZz7Rnzx65XC7t2bNHycnJ8vHxUefOnTV69OhLvrixJTExMfLy8lJ+fr4kae/everZs6cCAwMlnV1BDAwMlMlk0qBBgxQSEqKioqJLfp+vv/5aY8aMUdeuXWU2m3XnnXequLhYZWVlrXk6AAD8pNhsNg0YMECZmZlyOBwqKCjQvn37PLt358rNzdWZM2fkdrtVVFSkLVu2KC4uTpLUu3dvmUwmbdmyRXV1ddq6daskqU+fPq1WqyG2VisqKtSpU6dGFwueuz3o7+/f6PktFRUVCg4O9rwODg5utKLVoUOHRsujDccrKyvldDqbjC0vL2/V8/Hy8lJ8fLx2796t66+/Xrt27Wr0L8fOnTu1efNmT+ByOByqrKy85Pex2+1au3atPvroo0bt5eXlbK8CAHABKSkpWrVqlWbNmiU/Pz+lpqYqPDxc+fn5WrJkidLS0iRJe/bsUXp6uurr6xUYGKgxY8Zo6NChkiSLxaIpU6YoPT1dn3zyicLCwjRlypRWe/SIZJAgFxAQoIqKCrndbk+Ys9vtnoftnRvwJKlTp06y2+2eJVC73a5OnTp5jp85c0YOh8MT5hr6+vv7y2w2y263e5Y9T5486Vkps9lsqq2t9cxz6tSpyz6nhIQELV68WGPGjFFRUZGmTJki6ex1b++9955mzpypXr16yWQy6fe///155/D29pYk1dbWei6mPLemoKAgJSUlnff/IAAAQPP8/Pw0derUJu0xMTGeECdJkyZNuuA8UVFRev7551u9vgaG2FptCDRbtmyR0+lUTk7OBbcaBw0apM8++0ynT59WZWWlPvvssyZhJjMzU/X19crPz9ff//53DRw4UCaTSQMHDtS6detUU1OjsrIyffnll56xkZGRys/Pl91uV3V1tTZu3NhozoCAAJ04ceKizikqKkp+fn7685//rH79+qlDhw6S5AmKHTt2lHT2uXHN3e7csWNHBQYGKjs7Wy6XS9u3b9fx48c9x2+99VZt3LjRM766utpzAwgAADA+Q6zIWSwWTZ48WX/+85+1fv169e/f/7x3cTYYO3asampq9Morr0g6e83Z2LFjPccDAgLUoUMHPf/88/L29lZqaqrCwsIkSQ8//LAyMjI0Z84cWSwW3XLLLRo2bJgkqW/fvoqPj9crr7wif39/3XHHHdq3b59n3sTERK1cuVJfffWVhgwZooceeuiC55WQkKDMzEz96le/8rR17dpVo0eP1sKFC+Xl5aUhQ4aoV69ezc7xyCOPaM2aNVq3bp1uvvnmRn0HDBggh8Ohd955R3a7XT4+Purbt68GDhx4wboAAIAxeLnPvZXiGtDw+JHmtitxcWo2/Gdbl9DqfJImt3UJAHDNKPh1ylWdP/pPa67q/O2FIbZWAQAA0JQhtlaNqOGulvM59yJJAACAy3XNba2idbC1CgC4Emyttg62VgEAAAyKIAcAAGBQBDkAAACDIsgBAAAYFEEOAADAoAhyAAAABkWQAwAAMCiCHAAAgEHxzQ4AAOBHFzF2VFuX8JPAihwAAIBBEeQAAAAMiiAHAABgUAQ5AAAAgyLIAQAAGBRBDgAAwKAIcgAAAAZFkAMAADAoghwAAIBBEeQAAAAMiiAHAABgUAQ5AAAAgyLIAQAAGBRBDgAAwKAsbV0AjMknaXJblwAAwDWPFTkAAACDYkUOl6XuaEFbl9DqrGHRkqTrn/ifNq6kdR1c8ou2LgEAcJWwIgcAAGBQBDkAAACDIsgBAAAYFEEOAADAoAhyAAAABkWQAwAAMCiCHAAAgEER5AAAAAyKIAcAAGBQBDkAAACDIsgBAAAYFEEOAADAoAhyAAAABkWQAwAAMCiCHAAAgEER5AAAAAyKIAcAAGBQBDkAAACDIsgBAAAYlKWtCwAAAGhvqqqqlJ6erv3798vf31/JyclKSEho0m/Tpk3auXOn7Ha7/P39NWLECN1xxx2e47Nnz9bp06dlMp1dO+vZs6dmzpzZanUS5AAAAH4gIyNDZrNZ8+fPV3FxsZYuXaqIiAiFh4c36ud2uzVhwgRFREToxIkTWrx4sYKCgjRo0CBPn2nTpumGG264KnWytQoAAHAOh8OhnJwcjRs3Tj4+PoqJiVFsbKyys7Ob9B0zZoy6desms9ms0NBQxcbGqqCg4EerlRU5AACAc5SWlspkMik0NNTTFhERoYMHD15wnNvtVn5+vm655ZZG7StWrJDb7VZkZKTuu+8+RUZGtlqtBDkAAIBzOBwO+fr6Nmrz9fWVw+G44LhPP/1Ubrdbw4YN87RNnDhRUVFRkqTNmzfrjTfe0Jw5c9ShQ4dWqZWtVQAAgHPYbDZVV1c3aqupqZHNZmt2zNatW5WVlaXp06fLarV62qOjo+Xt7S1vb28lJSXJ19dX+fn5rVYrQQ4AAOAcISEhcrlcKi0t9bQVFxc3udGhwfbt2/X555/r17/+tYKCgn6sMiUR5AAAABqx2WwaMGCAMjMz5XA4VFBQoH379mnw4MFN+mZnZ2vdunV68skn1aVLl0bH7Ha7CgoKVF9fr7q6Om3atElVVVXq1atXq9Xabq6Rmz17th599NGrdnvuxaitrdXbb7+t/Px89e3bV48//nib1QIAANpOSkqKVq1apVmzZsnPz0+pqakKDw9Xfn6+lixZorS0NEnS+vXrVVlZqQULFnjGJiQkaPz48aqpqdHq1at14sQJWa1WRUZG6oknnpC/v3+r1dluglx7kJOTo9OnT2vhwoUym81tXQ4AAGgjfn5+mjp1apP2mJgYT4iTpHnz5jU7R3h4uGbPnn1V6mvwk9tadTqdlz3WbrcrJCSk3YQ4t9stl8vV1mUAAIB2qsUVudmzZ2vkyJHKysqS3W5Xv379NGHCBO3evVvbt2/XM8884+k7ffp0zZ07VyEhIVq5cqWsVqvKyspUUFCgiIgIPf744/r888+1c+dOBQQEaNKkSZ5bciWpqKhI77//vioqKhQXF6fU1FTPnR95eXlav369ysrKFBYWptTUVM9zWGbPnq0RI0YoOztbpaWlSktLazaMlZSUaM2aNSouLlZgYKCSk5MVGxurzMxMbdy4UW63W/v27dMDDzyg4cOHn3eOHTt2aPv27erRo4e2b9+uDh06KCUlRf3795ckVVdXa+3atfrmm2/k5eWlYcOG6Z577pHJZFJmZqaOHz+uiRMnSpLKysr00ksvafHixTKbzUpLS1OvXr108OBBHTp0SC+++KJOnz6tDz74QKWlpQoJCdGDDz6o6OhoSVJaWppiYmL03Xff6fDhw+rZs6cmTZokf39/1dXVKT09Xd9++61cLpeuu+46TZ8+XQEBAS3+iwEAANq/i1qR27t3r2bMmKF58+bp8OHD2rFjx0VNvnfvXt17771asGCBLBaLFi1apKioKC1cuFA33XST1q5d26j/rl27NGPGDP32t79VaWmpPvvsM0nSoUOHtGrVKqWmpmrhwoW69dZbtWzZMtXV1XnG7t69W9OnT9eiRYuaDXFOp1PLli1T37599eqrr+qhhx7SihUrdOzYMd1zzz268847FR8fr7S0tGZDXIPCwkKFhoZq4cKFuuOOO5Seni632y1JWrlypcxms15++WW98MIL2r9/v/76179e1Gcmnb1wcvz48frjH/8oHx8fLV26VImJiVq4cKFGjx6tpUuXqrKystHn9stf/lKvvvqqnE6nvvjiC0nSzp07VV1drVdeeUULFy7U+PHjG90SDQAAjO2igtxtt92mwMBA+fn56cYbb1RxcfFFTT5gwAB169ZNVqtVcXFxslgsGjp0qEwmk+Lj45vMM3LkSAUHB8vPz09JSUnavXu3JGnbtm269dZb1bNnT5lMJg0dOlQWi0WFhYWNagwODpa3t3ez9RQWFsrhcGjMmDGyWCzq06ePbrzxRu3ateuizudcnTt31i233OKpp6KiQqdOndKpU6f0zTff6IEHHpDNZlPHjh01atQoz7lcjKFDhyo8PFxms1n79+9XSEiIhgwZIrPZrISEBIWFhSkvL8/Tf9iwYQoNDZW3t7cGDhzo+VzNZrOqqqo8T6ju1q1bkwccAgAA47qomx06derk+dnb21sVFRUXNXnHjh0bjTt3S89qtTZ5QvK5z14JDg72vI/dbtfOnTu1detWz/H6+vpGdVzMc1vKy8sVGBgok+n/8uu573Mpzj2XhvDocDh05swZOZ1OPf/8857jbrf7kp4rc27fiooKBQcHNzoeHBys8vLyZmtp+FyHDBmikydP6p133lF1dbUSEhKUnJzcbq4BBAAAV+ay71q12Wyqra31vL6cMPRDJ0+ebPRzQ4AMCgpSUlKSxo4d2+xYLy+vFucPDAxUeXm5XC6XJ8w13ODQWoKCgmSxWLRgwYLzBqYffm6nTp1q0ufcc+nUqZPsdnuj4w3XKrbEbDbr7rvv1t13362ysjItWbJEoaGhLW4bAwAAY7jsu1YjIiJUUlKiQ4cOqa6uTp9++ukVF/PVV1/p5MmTqqqq0oYNGxQfHy9JGj58uL7++msVFhbK7XbL4XAoLy9PNTU1lzR/jx49ZLVatWnTJjmdTh04cEB5eXkaNGjQFdfeoFOnTurbt68+/PBDVVdXy+Vy6fjx4zpw4IAkKTIyUvn5+bLb7aqurtbGjRsvOF///v1VWlqqXbt2yel0avfu3Tp69KhuvPHGFmtpuAHC5XLJx8dHZrO50WokAAAwtstekQsNDdXYsWP1+uuvy2q1Kjk5Wdu2bbuiYgYNGqTFixeroqJCsbGxnhW47t2765FHHlFGRoaOHz8uq9Wq6OhoXX/99Zc0v8Vi0bRp07RmzRpt3LhRgYGBmjBhgsLCwq6o7h+aMGGCPv74Y82bN081NTXq0qWLxowZI0nq27ev4uPj9corr8jf31933HGH9u3b1+xc/v7+mjZtmj744AOtXr1a1113naZNm3ZRDxM8deqUVq9erfLyctlsNsXHx5/3qdQAAMCYvNwNt1oCl6DuaEFbl9DqrGFnH+ly/RP/08aVtK6DS37R1iUAQBM1G/7zqs7vkzT5qs7fXrDPBgAAYFA/ua/ostvtzX5dxksvvdTkDtDmvPfee+d9LEnD96cBAIDLZx4wuq1L+ElgaxWXha1V42BrFUB7dLX/Hmn4M/2njq1VAAAAgyLIAQAAGBRBDgAAwKAIcgAAAAZFkAMAADAoghwAAIBBEeQAAAAMiiAHAABgUAQ5AAAAgyLIAQAAGBRBDgAAwKAIcgAAAAZFkAMAADAoghwAAIBBEeQAAAAMiiAHAABgUAQ5AAAAgyLIAQAAGBRBDgAAwKAIcgAAAAZFkAMAADAoghwAAIBBebndbndbFwEAAK4tdUcLrur81rDoqzp/e8GKHAAAgEFZ2roAGNP39sq2LqHVdQv2lyTd/05WG1fSuj6cNESStCb3cBtX0rpS4iLaugQAaHOsyAEAABgUQQ4AAMCgCHIAAAAGRZADAAAwKIIcAACAQRHkAAAADIogBwAAYFAEOQAAAIMiyAEAABgUQQ4AAMCgCHIAAAAGRZADAAAwKIIcAACAQRHkAAAADMrS1gUAAAC0N1VVVUpPT9f+/fvl7++v5ORkJSQkNOnndrv18ccfa/v27ZKkm2++WT//+c/l5eUlSTp06JDS09N19OhRhYWF6dFHH1VUVFSr1cmKHAAAwA9kZGTIbDZr/vz5+rd/+zetXr1aR44cadJv27Ztys3N1QsvvKAXX3xReXl5+vrrryVJ9fX1Wr58uQYPHqxFixZp6NChWr58uerr61utToIcAADAORwOh3JycjRu3Dj5+PgoJiZGsbGxys7ObtJ3586duv322xUUFKTAwECNHj1aO3fulCQdOHBATqdTo0aNktVqVWJiotxut7777rtWq5UgBwAAcI7S0lKZTCaFhoZ62iIiIs67IldSUqKIiAjP68jISJWUlDQ61rDN2jBPw/HWQJADAAA4h8PhkK+vb6M2X19fORyOFvs29HO73c3OU1NT02q1EuQAAADOYbPZVF1d3aitpqZGNpvtvH3PDWYN/by8vJock6Tq6mr5+Pi0Wq0EOQAAgHOEhITI5XKptLTU01ZcXKzw8PAmfbt27ari4uJG/bp27eo5dvjwYbndbs/xI0eOeI63BoIcAADAOWw2mwYMGKDMzEw5HA4VFBRo3759Gjx4cJO+Q4YM0Zdffqny8nKVl5fryy+/1NChQyVJvXv3lslk0pYtW1RXV6etW7dKkvr06dNqtfIcOQAAgB9ISUnRqlWrNGvWLPn5+Sk1NVXh4eHKz8/XkiVLlJaWJkm69dZbdeLECdpkmr8AACAASURBVP3ud7+TdPY5crfeeqskyWKxaMqUKUpPT9cnn3yisLAwTZkyRRZL68UvL/e5633ARfreXtnWJbS6bsH+kqT738lq40pa14eThkiS1uQebuNKWldKXETLnQC0W3VHC67q/Naw6Ks6f3vB1ioAAIBBEeQAAAAMyrBBbvbs2frHP/7RpjXU1tZq6dKlevrpp/XWW28122/Hjh167bXXfsTKAADAtYCbHa5ATk6OTp8+rYULF8psNrd1OQAA4Bpj2BW51uJ0Oi97rN1uV0hISLsMcVdyXgAAwBhafUVu9uzZGjlypLKysmS329WvXz9NmDBBu3fv1vbt2/XMM894+k6fPl1z585VSEiIVq5cKavVqrKyMhUUFCgiIkKPP/64Pv/8c+3cuVMBAQGaNGmSoqKiPOOLior0/vvvq6KiQnFxcUpNTZXVapUk5eXlaf369SorK1NYWJhSU1MVGRnpqXHEiBHKzs5WaWmp0tLSmg1jJSUlWrNmjYqLixUYGKjk5GTFxsYqMzNTGzdulNvt1r59+/TAAw9o+PDhF/UZvf/++/rb3/6mmpoaXXfddXrwwQcVExOjiooKzZkzR6+88or8/c/eQfn999/rjTfe0B/+8AeZzWZt375dmzZt0qlTp9SjRw+NHz9enTt39nyeDz/8sDZv3iyXy6Xf/va3+vDDD5Wdna36+noFBwdr0qRJ532gIQAAMJ6rsrW6d+9ezZgxQ1arVYsWLdKOHTs8AaulcU8++aS6du2qJUuWaNGiRbr77rt1//33KzMzU2vXrtVTTz3l6b9r1y7NmDFDNptNb775pj777DPde++9OnTokFatWqVp06ape/fuys7O1rJly/Tv//7vnjp2796t6dOny9/fv9kQ53Q6tWzZMg0bNkxPPvmkCgoKtGzZMj333HO65557JEnHjx/XxIkTL+nz6d69u+666y75+vpqy5YtevvttzVv3jx16tRJvXv31t69ezVixAhJUnZ2tuLj42U2m5Wbm6uNGzdq6tSpCgkJ0eeff6533nlH/+///T/P3Lm5ufrNb34jq9Wq/fv36+DBg5o7d658fX119OhRdejQ4ZJqBQAA7ddV2Vq97bbbFBgYKD8/P914442NvrriQgYMGKBu3brJarUqLi5OFotFQ4cOlclkUnx8fJN5Ro4cqeDgYPn5+SkpKUm7d++WJG3btk233nqrevbsKZPJpKFDh8pisaiwsLBRjcHBwfL29m62nsLCQjkcDo0ZM0YWi0V9+vTRjTfeqF27dl3Gp/J/hgwZ4gmQt99+u+rq6nTs2DHPsezsbEmSy+XS7t27NWTI2eeAff311xozZoy6du0qs9msO++8U8XFxSorK/PMfeedd8rPz0/e3t4ym81yOBw6duyY3G63unbtqk6dOl1R7QAAtIYS79Cr+s+14qqsyJ0bFry9vVVRUXFR4zp27NhoXEBAgOe11WqVw+Fo1D8oKMjzc3BwsOd97Ha7du7c6fkqDEmqr69vVMe5Y5tTXl6uwMBAmUz/l3fPfZ/LtWnTJm3fvl0VFRXy8vJSTU2NKivPPmA3Li5Oq1ev1okTJ3Ts2DH5+PioR48envNau3atPvrooyZ1Nmyvnnteffr00ciRI7VmzRrZ7XYNGDBA9913n3x9fa+ofgAA0D78aHet2mw21dbWel5faRiSpJMnTzb6uSFABgUFKSkpSWPHjm12rJeXV4vzBwYGqry8XC6XyxPmGm5wuFz5+fnatGmTfv3rX6tr164ymUyNrhu0Wq2Kj49Xdna2jh075lmNO/e8zvddb81JTExUYmKiTp8+rbfffltffPGFxo0bd9n1AwCA9uNHu2s1IiJCJSUlOnTokOrq6vTpp59e8ZxfffWVTp48qaqqKm3YsEHx8fGSpOHDh+vrr79WYWGh3G63HA6H8vLyVFNTc0nz9+jRQ1arVZs2bZLT6dSBAweUl5enQYMGXXbNNTU1MpvN8vf3l8vl0l/+8pcmdQ0ZMkQ7d+5s8gW9t956qzZu3KgjR45Ikqqrq7V3795m36uoqEiFhYVyOp3y9vaW1Wq9qAALAACM4UdbkQsNDdXYsWP1+uuvy2q1Kjk5Wdu2bbuiOQcNGqTFixeroqJCsbGxnhW47t2765FHHlFGRoaOHz8uq9Wq6OhoXX/99Zc0v8Vi0bRp07RmzRpt3LhRgYGBmjBhgsLCwi675n79+qlfv356+eWX5e3trVGjRjXZ5o2OjpaXl5eioqI8W6bS2WsIHQ6H3nnnHdntdvn4+Khv374aOHDged+rpqZGa9euVVlZmSwWi/r166fbb7/9smsHAADti5fb7Xa3dRFo6j/+4z+UkJBw0Y80+bF9b69s6xJaXbfgs498uf+drDaupHV9OOns9vya3MNtXEnrSomLaOsSAFyBq/33SMOf6T911/wDgdujoqIiHTp0yLNVDAAAcD7X/Fd02e12zZs377zHXnrpJQUHB1/UPO+99955H0uSkJCg8ePHX3Q9//3f/63c3Fw9+OCD8vHxuehxAADg2sPWKi4LW6vGwdYqgPaIrdXWwdYqAACAQRHkAAAADIogBwAAYFAEOQAAAIMiyAEAABgUQQ4AAMCgCHIAAAAGRZADAAAwKIIcAACAQRHkAAAADIogBwAAYFAEOQAAAIMiyAEAABgUQQ4AAMCgCHIAAAAGRZADAAAwKIIcAACAQRHkAAAADIogBwAAYFAEOQAAAIMiyAEAABgUQQ4AAMCgCHIAAAAG5eV2u91tXQQAALi2fG+vvKrzdwv2v6rztxesyAEAABiUpa0LgDF91iOurUtodWOLciVJdUcL2riS1mUNi5bEeRlFw3kBwMVgRQ4AAMCgCHIAAAAGRZADAAAwKIIcAACAQRHkAAAADIogBwAAYFAEOQAAAIMiyAEAABgUQQ4AAMCg+GYHAACAy1BVVaX09HTt379f/v7+Sk5OVkJCwnn7btq0STt37pTdbpe/v79GjBihO+64w3N89uzZOn36tEyms2tsPXv21MyZM1usgSAHAABwGTIyMmQ2mzV//nwVFxdr6dKlioiIUHh4eJO+brdbEyZMUEREhE6cOKHFixcrKChIgwYN8vSZNm2abrjhhkuqga1VAACAS+RwOJSTk6Nx48bJx8dHMTExio2NVXZ29nn7jxkzRt26dZPZbFZoaKhiY2NVUHDl3xXNihwAAMAlKi0tlclkUmhoqKctIiJCBw8ebHGs2+1Wfn6+brnllkbtK1askNvtVmRkpO677z5FRka2OBdBDgAA4BI5HA75+vo2avP19ZXD4Whx7Keffiq3261hw4Z52iZOnKioqChJ0ubNm/XGG29ozpw56tChwwXnIsgBAAD8QFpaWrOra9HR0XrooYdUXV3dqL2mpkY2m+2C827dulVZWVl6+umnZbVaG83ZICkpSVlZWcrPz1dsbOwF5yPIAQAA/MBTTz11weMOh0Mul0ulpaUKCQmRJBUXF5/3RocG27dv1+eff66nn35aQUFBrVInNzsAAABcIpvNpgEDBigzM1MOh0MFBQXat2+fBg8efN7+2dnZWrdunZ588kl16dKl0TG73a6CggLV19errq5OmzZtUlVVlXr16tViHazIAQAAXIaUlBStWrVKs2bNkp+fn1JTUz0rcvn5+VqyZInS0tIkSevXr1dlZaUWLFjgGZ+QkKDx48erpqZGq1ev1okTJ2S1WhUZGaknnnhC/v7+Ldbg5Xa73Vfn9PBT9lmPuLYuodWNLcqVJNUdvfLbwdsTa9jZ6y44L2NoOC/gp+57e+VVnb9bcMsh6KeArVUAAACDIsgBAAAYFEEOAADAoAhyAAAABsVdqwAA4Ee3/VDFVZ2fmx0AAADQrhHkAAAADIog1wpWrlypdevW/SjvlZ2drddff/1HeS8AANC+EeTasbKyMk2fPl1Op9PTNnjwYM2cObMNqwIAAO0FQa4NuVyuti4BAAAYGHetXoZDhw4pPT1dpaWl6t+/v7y8vCRJO3bs0Pbt2/XMM894+k6fPl1z585VSEiIVq5cKavVKrvdroMHD2rq1Kmqq6vT+vXrdeLECfn4+Ojmm2/WPffcI0n64x//KEl69tlnJUlPPvmkjh071ug9CgoK9MEHH6i0tFQhISF68MEHFR199it+0tLSFBMTo++++06HDx9Wz549NWnSpIv67jYAAND+sSJ3ierr67V8+XINHjxYixYt0sCBA5WTk3PR43ft2qWkpCT98Y9/VHR0tGw2myZMmKBFixZp+vTp+vrrr/W3v/1NkvT0009LkhYtWqS0tDT16tWr0VxVVVVaunSpEhMTtXDhQo0ePVpLly5VZWVlo/f75S9/qVdffVVOp1NffPFFK3wKAACgPSDIXaLCwkI5nU6NGjVKZrNZAwcOVPfu3S96fGxsrKKjo2UymWS1WtW7d29FRETIZDIpMjJSgwYNUn5+/kXN9fe//10hISEaMmSIzGazEhISFBYWpry8PE+fYcOGKTQ0VN7e3ho4cKCKi4sv+ZwBAED7xNbqJaqoqFCnTp0826mS1Llz54seHxQU1Oh1YWGhPv74Y5WUlKi+vl719fUaOHDgRdcSHBzcqC04OFjl5eWe1wEBAZ6fvb295XA4LrpWAADQvhHkLlFAQIAqKirkdrs9Yc5ut6tLly6y2Wyqra319K2oaPrU6nMDoCStWLFCI0eO1IwZM2S1WvXBBx802hq9kE6dOslutzdqs9vt6tev36WeFgAAMCC2Vi9Rr169ZDKZtGXLFjmdTuXk5KioqEiSFBERoZKSEh06dEh1dXX69NNPW5yvpqZGfn5+slqtKioq0q5duzzHOnbsKC8vL504ceK8Y/v376/S0lLt2rVLTqdTu3fv1tGjR3XjjTe2yrkCAID2jRW5S2SxWDR58mT9+c9/1vr169W/f38NGDBAkhQaGqqxY8fq9ddfl9VqVXJysrZt23bB+VJSUvTRRx8pIyND119/veLj43XmzBlJZ7dCk5KS9Nprr8npdGrGjBmNxvr7+2vatGn64IMPtHr1al133XWaNm0ad6UCAHCN8HK73e62LgLG81mPuLYuodWNLcqVJNUdLWjjSlqXNezs42g4L2NoOC/gp25N7uGrOn9KXMRVnb+9YGsVAADAoAhyAAAABkWQAwAAMCiCHAAAgEER5AAAAAyKIAcAAGBQBDkAAACDIsgBAAAYFEEOAADAoAhyAAAABkWQAwAAMCiCHAAAgEER5AAAAAyKIAcAAGBQBDkAAACDIsgBAAAYFEEOAADAoAhyAAAABkWQAwAAMCiCHAAAgEER5AAAAAyKIAcAAGBQBDkAAACDIsgBAAAYFEEOAADAoAhyAAAABuXldrvdbV0EAAC4tqzJPXxV50+Ji7iq87cXrMgBAAAYlKWtC4Ax3f9OVluX0Oo+nDREkvRZj7g2rqR1jS3KlfTT+501/L7qjha0cSWtyxoWLemn+/sC0LpYkQMAADAoghwAAIBBEeQAAAAMiiAHAABgUNzsAAAAcBmqqqqUnp6u/fv3y9/fX8nJyUpISDhv38zMTG3YsEFWq9XT9uKLL6pLly6SpEOHDik9PV1Hjx5VWFiYHn30UUVFRbVYA0EOAADgMmRkZMhsNmv+/PkqLi7W0qVLFRERofDw8PP2j4+P18SJE5u019fXa/ny5UpMTNSIESO0bds2LV++XHPnzpXFcuGoxtYqAADAJXI4HMrJydG4cePk4+OjmJgYxcbGKjs7+5LnOnDggJxOp0aNGiWr1arExES53W599913LY4lyAEAAFyi0tJSmUwmhYaGetoiIiJ05MiRZsfk5eXp2Wef1bx58/TVV1952ktKShQRESEvL69Gc5WUlLRYB1urAAAAl8jhcMjX17dRm6+vrxwOx3n7x8fH65ZbblFAQIAKCwv11ltvydfXVwkJCc3OVVNT02IdBDkAAIAfSEtL08GDB897LDo6Wg899JCqq6sbtdfU1Mhms513TNeuXRuNT0xMVE5OjhISEmSz2ZqEturqavn4+LRYJ0EOAADgB5566qkLHnc4HHK5XCotLVVISIgkqbi4uNkbHX7Iy8tLbrdb0tmQ9+WXX8rtdnu2V48cOaKRI0e2OA/XyAEAAFwim82mAQMGKDMzUw6HQwUFBdq3b58GDx583v65ubk6c+aM3G63ioqKtGXLFsXFnf1u7969e8tkMmnLli2qq6vT1q1bJUl9+vRpsQ5W5AAAAC5DSkqKVq1apVmzZsnPz0+pqameFbn8/HwtWbJEaWlpkqQ9e/YoPT1d9fX1CgwM1JgxYzR06FBJksVi0ZQpU5Senq5PPvlEYWFhmjJlSouPHpEIcgAAAJfFz89PU6dOPe+xmJgYT4iTpEmTJl1wrqioKD3//POXXANbqwAAAAbFihwAAPjRfbCn+KrOnxIXcVXnby9YkQMAADAoghwAAIBBEeQAAAAMiiAHAABgUAQ5AAAAgyLIAQAAGBRBDgAAwKAIcgAAAAZFkAMAADAoghwAAIBBEeQAAAAMiiAHAABgUAQ5AAAAg7K0dQFoavbs2Ro5cqSysrJ04sQJxcfHKzk5WStXrlRBQYF69Oihxx9/XB06dNBbb72lgoIC1dbWKjIyUikpKQoPD5ck1dXVad26ddq7d6/q6+sVFxenBx54QN7e3m18hgAAoDWwItdO5eTkaObMmZo7d67y8vK0ZMkSJScna8GCBXK73dqyZYskqX///po7d65effVVRUVF6d133/XM8cknn6i0tFQvvPCCXn75ZZWXl+svf/lLG50RAABobQS5duq2225TQECAAgMDFRMTox49eigqKkpWq1VxcXE6dOiQJOnmm2+Wj4+PrFar7r77bhUXF6u6ulput1vbtm3TAw88ID8/P/n4+CgpKUl79uxp4zMDAACtha3VdiogIMDzs9VqVceOHT2vvb295XA45HK5PFunlZWV8vLykiRVVlaqvr5etbW1mj9/vmec2+2W2+3+8U4CAABcVQQ5A9u1a5dyc3M1c+ZMde7cWdXV1Xr22Wfldrvl5+cnq9Wql156SYGBgW1dKgAAuArYWjWwmpoaWa1W+fn5qba2Vp988onnmMlk0vDhw7V27VqdPn1aklReXq5vv/22rcoFAACtjBU5AxsyZIj279+vF154QX5+frrnnnv09ddfe47/4he/0F/+8hctWLBAVVVV6tSpk0aMGKF+/fq1YdUAAKC1EOTaod/97neNXk+cOLHR6+HDh2v48OGSpKlTpzY6NnToUM/PVqtVycnJSk5OvkqVAgCAtsTWKgAAgEER5AAAAAyKIAcAAGBQBDkAAACDIsgBAAAYFEEOAADAoAhyAAAABkWQAwAAMCiCHAAAgEER5AAAAAyKIAcAAGBQBDkAAACDIsgBAAAYFEEOAADAoAhyAAAABkWQAwAAMCiCHAAAgEER5AAAAAyKIAcAAGBQBDkAAACDIsgBAAAYFEEOAADAoAhyAAAABkWQAwAAMCiCHAAAgEER5AAAAAzKy+12u9u6CAAAcG25/52sqzr/h5OGXNX52wtW5AAAAAzK0tYFwJiu9v9JtYWG/3sr+HVKG1fSuqL/tEaSVHe0oI0raV3WsGhJ0prcw21cSetKiYuQJF3/xP+0cSWt6+CSX0j66f33Jf3ff2O49lRVVSk9PV379++Xv7+/kpOTlZCQcN6+b7zxhgoK/u/P4fr6eoWGhmr27NmSpNmzZ+v06dMymc6usfXs2VMzZ85ssQaCHAAAwGXIyMiQ2WzW/PnzVVxcrKVLlyoiIkLh4eFN+s6YMaPR67S0NPXp06dR27Rp03TDDTdcUg1srQIAAFwih8OhnJwcjRs3Tj4+PoqJiVFsbKyys7NbHFtWVqb8/HwNGXLl1/GxIgcAAHCJSktLZTKZFBoa6mmLiIjQwYMHWxyblZWlmJgYde7cuVH7ihUr5Ha7FRkZqfvuu0+RkZEtzkWQAwAAuEQOh0O+vr6N2nx9feVwOFocm5WVpaSkpEZtEydOVFRUlCRp8+bNeuONNzRnzhx16NDhgnMR5AAAAH4gLS2t2dW16OhoPfTQQ6qurm7UXlNTI5vNdsF58/PzderUKd10001N5myQlJSkrKws5efnKzY29oLzEeQAAAB+4KmnnrrgcYfDIZfLpdLSUoWEhEiSiouLz3ujw7mysrIUFxcnHx+fVqmTIAcAAH50+/YcubpvMOnqTm+z2TRgwABlZmbqkUceUXFxsfbt26dnn3222TG1tbXas2ePpkyZ0qjdbrfr5MmT6t69u9xut7Zu3aqqqir16tWrxToIcgAAAJchJSVFq1at0qxZs+Tn56fU1FTPilx+fr6WLFmitLQ0T//c3Fx16NBBvXv3bjRPTU2NVq9erRMnTshqtSoyMlJPPPGE/P39W6yBIAcAAHAZ/Pz8NHXq1PMei4mJaRTiJCkhIeG8DwwODw/3PBj4UvEcOQAAAIMiyAEAABgUQQ4AAMCgCHIAAAAGRZADAAAwKIIcAACAQRHkAAAADIogBwAAYFAEOQAAAIMiyAEAABgUQQ4AAMCgCHIAAAAGRZADAAAwKIIcAACAQRHkAAAADIogBwAAYFAEOQAAAIMiyAEAABjUNR/kZs+erX/84x9X9T0yMzO1YsWKVptvw4YNSk9Pb7X5AACAMVnaugCjSktL0+DBgzV8+PAf/b2TkpJ+9PcEAADtzzW/IgcAAGBUrMhJKioq0vvvv6+KigrFxcUpNTVVdXV1evfdd1VUVCSn06no6GilpqYqKChIn3zyifLz81VYWKi1a9dq6NChevjhh3XkyBGtXbtW33//vcxmsxITEz2rZ06nU++++65yc3MVHBysxx57TN27d79gXZ9//rm2bNmimpoaderUSSkpKbrhhhuUmZmp48ePa+LEicrIyNDOnTs9Y+rq6pSUlKR77rlH5eXlev/995Wfny+bzaZRo0YpMTHxqn6WAADgx0OQk7Rr1y7NmDFDNptNb775pj777DONGjVKw4YN069+9Su5XC6tWrVKGRkZmjp1qpKTk/XPf/6z0dZqTU2NXn/9dd1+++2aNm2anE6nSkpKPO+xb98+TZ48WY899pjWrVunjIwM/eY3v2m2pmPHjmnr1q2aNWuWAgMDVVZWJpfL1aTfww8/rIcffliSdOjQIS1evFhxcXFyuVx68803FRcXp0mTJqm8vFx/+tOfFBoaqn79+rXyJwgAANoCW6uSRo4cqeDgYPn5+SkpKUm7d++Wv7+/brrpJnl7e8vHx0dJSUk6ePBgs3Pk5eUpICBAt99+u6xWq3x8fNSzZ0/P8ejoaP3sZz+TyWTSkCFDdPjw4QvW5OXlpfr6eh09elROp1OdO3fWdddd12z/06dPa/ny5XrooYcUFRWlf/3rX6qsrNRdd90li8WiLl26aPjw4dq9e/elf0AAAKBdYkVOUlBQkOfn4OBgVVRUqLa2VmvXrtW3336rM2fOSDq76uZyuWQyNc2/J0+evGDQCggI8Pzs7e2turo6OZ1Omc3m8/YPCQnRgw8+qE8//VRHjhxRv379dP/99yswMLBJX6fTqbfeeksJCQn/X3v3HhVlue8B/DvAcJdhBlRgg+K9vCDIVTyuI1ZettjeFWm2zajVybJypx47bdchU2yd2qZ0lhq58razVEzdZglCJnlJBVGKHXIMS4ybkA4MCAwMDOcPF5PDxQsz8Mz78v2s1VrM+06sb3sj/uZ5n+f3Q1hYGABAq9VCp9Nh2bJlpvcZjUYMHz78Lv9rEBERkVSwkMOtIuz2r1UqFY4ePYqKigosX74cKpUKxcXF+J//+R+0trZ2+j3UajXOnz9v1Vzh4eEIDw9HQ0MDdu/ejYMHDyI+Pr7D+1JSUuDs7IzZs2eb5fHy8sKqVausmomIiIhsBx+tAjhx4gSqqqpQV1eHI0eOIDQ0FHq9HkqlEq6urqirq0NqaqrZv+Ph4YHr16+bXo8bNw46nQ7Hjh2DwWCAXq/HlStXup2poqICly5dgsFggFKphFKphEKh6PC+kydPorCwEM8995zZSmFgYCCcnZ2RkZGBpqYmGI1GlJWVoaioqNuZiIiIyLZwRQ5AWFgYNmzYAJ1Oh6CgIMycORP19fXYvn073njjDahUKjz00EP44YcfTP9OTEwMPvnkE5w4cQKRkZGYM2cOFi9ejM8//xyHDx+GUqlETEyM2T65+2EwGHDw4EFcu3YN9vb2GDp0KJ5++ukO78vJycGNGzewYsUK07Xp06djxowZePnll3HgwAG89dZbMBgMGDhwIB599NFu5SEiIiLbo2jt6lkh0R08sS1LdASr2/98JADg578+JTiJdQ373z0AAMO1nwUnsS6lzzAAwJ4f7nxwSGqeGv8HAMCIV/4pOIl1FW56DID8/nwBv/8Zo/vT0z/jbT9zcsdHq0REREQSxUerAmm1WiQmJnZ6LyEhARqNppcTERERkZSwkBNIo9EgKSlJdAwiIiKSKD5aJSIiIpIoFnJEREREEsVCjoiIiEiiWMgRERERSRQLOSIiIiKJYiFHREREJFEs5IiIiIgkioUcERERkUSxkCMiIiKSKBZyRERERBLFQo6IiIhIoljIEREREUkUCzkiIiIiiWIhR0RERCRRLOSIiIiIJIqFHBEREZFEsZAjIiIikigWckREREQSxUKOiIiISKIcRAcgIiIikqJvv/0WZ8+eRVlZGcLCwrBgwYI7vv+bb77B119/jaamJoSEhOCpp56CUqkEANy4cQOffPIJioqKoNFoMHfuXDzwwAN3zcAVOSIiIqJuUKlUmDFjBiZOnHjX9168eBEZGRlYvHgx1qxZg+vXr+Pw4cOm+9u2bUNAQADWrl2LRx99FB9//DFqa2vv+n1ZyBERERF1Q0hICIKDg+Hm5nbX9549exbR0dHw8/ODq6srZs6cibNnzwIAKioqUFxcjNjYWDg6OiIklphVUAAAIABJREFUJAR+fn7Izc296/flo1Xqlv3PR4qO0GOG/e8e0RF6hNJnmOgIPeKp8X8QHaFHFG56THSEHiHXP19Ed1NeXo6goCDTa39/f9TU1ODmzZsoLy+Hl5cXnJ2dze6Xl5ff9fuykCMiIqJeJ9cPK11pbGyEi4uL6XXb142NjR3uAYCzszN0Ot1dvy8LOSIiIqJ2kpKSUFhY2Om9YcOGYdmyZff1/ZycnKDX602vGxoaTNfb3wMAvV4PJyenu35fFnJERERE7SxZssSq38/X1xclJSUIDQ0FAJSWlsLDwwPu7u7w9fXF9evXodfrTY9XS0tLERYWdtfvy8MORERERN3Q0tICg8EAo9EIo9EIg8GAlpaWTt8bGRmJM2fOoLy8HPX19UhLS0NUVBQAYODAgfD398fhw4dhMBjw/fffo7S0FCEhIXfNoGhtbW216n8VERERUR/w1VdfITU11ezaH//4R8TGxkKr1SIxMREJCQnQaDQAbvWRy8jIgMFgQHBwMObNm9dpHzm1Wo2nnnrqnvrIsZAjIiIikig+WiUiIiKSKBZyRERERBLFQo6IiIhIoljIkU0xGo04ffo0DAaD6Cg9RqvV4sqVK6JjEBGRDLCPHNkUOzs77N+/H9HR0aKjWJ1Wq8W2bdtQUlIChUKBpKQkXLhwARcvXsT8+fNFx7NIbW0tlEolnJ2dYTQakZWVBYVCgYiICNjZ8fOiLamrq8PRo0dRUlKCxsZGs3tLly4VlIqIuouFHNmccePGIS8vz2wmnRzs2rULY8eOxdKlS7F8+XIAwIMPPogDBw4ITma55ORkzJs3DwEBATh06BD+9a9/wd7eHiUlJYiLixMdr9vKy8vh5uYGDw8P6PV6HD16FAqFAo888ggcHR1Fx+uW7du3w2AwIDQ0VLL/DV0xGAxITU1FTk4O6urqsH79ely8eBGVlZWYMmWK6HgWKygoQE5ODmpra7Fo0SJcvXoVer0eo0aNEh2NBGIhRzbHYDBgy5YtGDJkCNRqtdm9+Ph4MaGs4OrVq1i0aBHs7OygUCgA3Jq11zamRcoqKirg7+8PAMjOzsZ//ud/wsnJCYmJiZIu5LZt24YXXngBHh4eOHDgACoqKqBUKrFr1y7J/iz+8ssveO+990y9q+Rk37590Ol0eO6557Bp0yYAgJ+fH/bv3y/5Qi4zMxPffvstoqOjkZubCwBQKpXYu3ev6YMh9U0s5Mjm+Pn5wc/PT3QMq+vXrx9+++03DBw40HStvLy8Q7EqRXZ2dmhubkZlZSVcXFyg0WhgNBo7PLqTmhs3bmDgwIFobW3F999/j7feegtKpRIJCQmio3XbH/7wB1RXV6N///6io1jdDz/8gFWrVsHJycn0YcnT0xPV1dWCk1kuMzMTf/3rX+Hl5YWMjAwAgI+PDyorKwUnI9FYyJHNmTVrlugIPeLhhx9GcnIypk+fDqPRiHPnziE9PR3Tpk0THc1iY8aMwdatW1FXV2eaI3jt2jV4enoKTmYZpVIJvV6P8vJyaDQauLu7o6WlBc3NzaKjddvIkSOxceNGTJw4ER4eHmb3pL431cHBAUaj0exabW0t3NzcBCWyHr1eb/rQ11aktrS0wN7eXmQssgEs5MgmyXEvSHR0NNzc3HDq1Cmo1WpkZWUhNjYWwcHBoqNZ7C9/+QuysrJgb2+PiIgIAMDNmzclX5SHh4fjgw8+QGNjI/793/8dAFBcXAwvLy/Bybrv8uXL8PT0REFBgdl1hUIh+UIuJCQE//jHP0yP83U6HT7//HPThwspGzFiBNLT0zFz5kzTtczMTIwcOVJgKrIFHNFFNuf2vSDp6elYv349ysrK8Nlnn3EvCPW6ixcvwt7e3vQhQg4fKuSqubkZBw8exHfffYempiY4Ojpi0qRJ+POf/wwHB2mvW+h0OiQnJ+PmzZuorq6Gt7c3nJ2d8fLLL0OlUomORwJJ+yebZEmue0FOnz7d5T2pr4TIsaWF0WjE22+/jYSEBLODAYMHDxaYyjrq6+uRl5eH6upqeHp6IigoCK6urqJjWczBwQFxcXGIi4tDbW0t3N3dTY8hpU6lUuG//uu/cPXqVWi1WqjVagwePJjtfYiFHNkeue4FycrKMntdU1OD69evY+jQoZIv5OTY0sLOzs50iENOJzx/+eUXfPjhhxg4cCC8vLzw448/Yt++fVi0aBGGDh0qOp5V6PV6NDY2mn2o8Pb2FpjIcqmpqQgKCkJgYCACAwNN19PT0zF9+nRxwUg4FnJkc+S6F2TJkiUdrp0+fRrXrl0TkMa65NrSIiYmBlu2bMH06dOhVqvNVnekWhjs27cPTz31FMLCwkzXcnJysHfvXrz55psCk1muvLwc27dvR2lpaYd7be1IpCo1NRXHjx/H3LlzMWHCBNN1FnLEQo5szpw5c5CcnIzvvvsOer0eb7/9tmkviNxERUXhjTfewOOPPy46ikXk2tJi7969AID/+7//63BPqoVBRUWFWSEAABMmTMDu3bsFJbKePXv2YOTIkXj99deRkJCANWvW4ODBg7JYaVQqlXjttdewefNmlJaWYvbs2QAAbnMnFnJkc+S6F6R9W4SmpiZkZ2fDxcVFUCLrkWtLC6kWa3cyYMAAnD9/HuHh4aZrFy5ckEURXlJSgsWLF5u2Ybi4uODxxx/HmjVrEBkZKTidZRQKBfz9/fHGG29gy5Yt+OijjxAfHy+bPYDUfSzkyCa1traipaUFQMcCSKpee+21Dtc8PT3xl7/8RUAa65JzSwvg1pxcnU6HIUOGiI5isbi4OCQnJyMzMxMajQZarRaVlZWyWPFWKpWm/bTu7u7QarVwdXVFXV2d6GgWa1t569evHxYvXoy9e/fi73//u+n3JPVdbD9CNqekpASbN29Gc3OzqSu7g4MDFi5caBoDJUU3btwwe+3k5AR3d3dBaeheaLVabNu2DSUlJVAoFEhKSsKFCxdw8eJFzJ8/X3S8bquvr8e//vUv6HQ6qFQqjB07VhZNc7ds2YIxY8Zg4sSJOHjwIPLy8qBUKqFWq/HSSy+JjmeRlJQUzJ071+zayZMnkZOT0+n+W+o7WMiRzXn33XcRFhaGhx56CAqFAq2trTh27Biys7Pxt7/9TXQ86oIcW1ps3LgRw4cPx7Rp07B8+XKsW7cODQ0NeOedd7BmzRrR8egO2qanNDY2IioqSjanqYna46NVsjmVlZWYOnWqae+HQqFATEwMDh8+LDjZ/Vu3bt097WGRaq+1NnJtaXH16lUsWrQIdnZ2pv8fXVxc0NDQIDjZ/dm4cSNeffVVAHf+mZT6z2FDQwMyMzNRXFxs1nrk+++/x+LFiwUm657PPvvMtPVix44dXb4vPj6+dwKRTWIhRzZnzJgxyMvLMxtdlZeXh7FjxwpM1T2TJk0SHaFXyLWlRb9+/fDbb79h4MCBpmvl5eWmPodScftGfzn/TH788cdobW3F+PHjZdEK5/ZRcHI4jEI9g4Uc2YTbP20ajUZs27YNAQEBUKvVqKqqQnFxMYKCgsQF7KaoqCjREXqFXFtaPPzww0hOTsb06dNNj+rS09Mxbdo00dHuy+0nVAcOHNjpoY2ioqJeTNQzioqK8Pe//13y47jazJgxw/S11OcWU8+Rx087SV77T5t+fn6mr319fTF69OjejtQjampqUFRUhLq6OrP+T1I/2SnXlhbR0dFwc3PDqVOnoFarkZWVhdjYWLPVYqnZsGED1q9f3+H6xo0b8f777wtIZD3Dhg3DtWvXJH0oqiuXLl2Cl5cXvL29odPpcPDgQSgUCvzpT3/irNU+joUc2YS+8Gnz+++/xz/+8Q/0798f5eXl8PX1RVlZGYYNGyb5Qk6uLS2MRiPGjx+P8ePHi45isbY2Pq2traZ/2ly/fl3yfRoBYMGCBdi0aRMCAwM79DP84x//KCiVdezZs8fUwmj//v0AbrVb2bVrl+T/nJFlWMiRTbpx4wZKS0s7DGC/fcVHar788ks888wzmDBhApYtW4YVK1bgzJkzKCsrEx3NIq2trVCpVFi5ciUuXrwInU6HcePGyaKlxZtvvomwsDBERUVh0KBBouNY5PY+hm0HH9ooFAqzx3hSdejQIVRVVcHLywt6vV50HKvS6XTQaDRoaWlBQUEBEhMT4eDgwJP8xEKObM+RI0eQlpYGX19fsw3LCoVC0oVcVVVVh31kkZGRePPNN/HEE08ISmU5hUKBNWvWYP369ZLvnt/eq6++iuzsbHz44YdwcXFBZGQkIiIioNFoREe7b6tXrwYAJCUlmfUdUygUcHd3l0V7jpycHLz99tuyfNTo7OyMmpoalJWVwcfHB87OzmhubmZDYGIhR7bnm2++wZtvvglfX1/RUayqX79+qKmpgYeHB7y8vPDLL7/A3d1dFrMSAwICUFlZCR8fH9FRrGrQoEEYNGgQHn/8cRQUFCA7Oxtr1qxBQEAAIiMjERoaCicnJ9Ex70nbCUg597/z9vY2jeeSmylTpuC9995DS0sL4uLiAAA///yz7P7M0f1jIUc2x83NzezYvVxMmjQJP//8M0JCQjB16lR88MEHUCgUePjhh0VHs9iIESOwceNGREVFQa1Wm/Upk/r+PwCws7ODj48PfHx8UFRUBJ1Oh3PnzuHAgQN48sknJbcSmZeXh8LCQty8edPsg4TU+5FFREQgOTkZU6ZM6bBHbtSoUYJSWce0adMwfvx42NnZmQ4RtR/xV1VVJbnWOGQ5TnYgm5Ofn4/s7GxMnToV/fr1M7snxUdaXdFqtWhsbJTFymNSUlKn1xUKBV5//fVeTmM99fX1OH/+PLKzs3Ht2jVMmDABERERGDZsGIBb7S42bNiAdevWCU567w4fPoyTJ08iLCwMJ0+exOTJk3Hu3DmEhoZizpw5ouNZJCEhoct7iYmJvZhEjKVLl3Z6IpnkjStyZHOam5tRUFCAnJycDvc2bdokIJF1HDt2DGFhYaaVAjkVpXKd9bhixQqMHDkSU6ZMQVBQUIcms4GBgZI70XrmzBksXrwYfn5+OHPmDOLi4hAWFoa0tDTR0SzWF4q1O+G6TN/EQo5szp49e/CnP/0JoaGhstiA3eann37CF198gaFDhyIiIgLBwcFwcXERHcsq2lpbdEbKbS1Wr17d4RFdewsWLOilNNZRX19v6tNob2+PlpYWBAYGorCwUHAystS9jAMk+WEhRzbHaDRi4sSJki4AOvPSSy+hvr4eubm5yMrKQkpKCkaPHo3w8HCEhISIjmeR21tbtCflVVQPDw80NzejoqICN2/eNLsn1T1X/fv3R1lZGfz8/ODn54cTJ07A1dUVrq6uoqMRUTdwjxzZnK+//hrNzc2YMWOGrD9harVafPrpp7h06ZKkix3gVt+/29XU1CA9PR3jxo2T9GzPy5cvY8uWLWhuboZer4ezszP0ej3UarVkH+P9+OOPcHJywogRI1BUVITt27ejsbERc+fOlfwHir6Oe+T6Jq7Ikc3JzMw0FQLtG8q+8847glJZz+XLl5GTk4Pc3Fy4ubkhNjZWdCSLtT9l7OXlhWeffRbvvfeepAu5ffv24ZFHHsFDDz2EZcuW4f3330dqaqpkB7IbjUYolUrTrNXAwECsWrVKcCqyFq7L9E0s5MjmSL0FQlcOHDiACxcuAABCQ0Px6quvIiAgQHCqntPQ0IDa2lrRMSxSWVmJmJgYs2vTpk1DQkICHnnkEUGpus/Ozg4fffRRl6eMSRra70lt24Zyp1O7JF8s5MjmjBw5UnSEHtHY2Ij4+HgMHz5cdBSr27Fjh9lrg8GAwsJCREREiAlkJS4uLtDr9XB1dYVKpUJ5eTnc3Nw6jI6TkuHDh+PKlSumVTmShl9//RUpKSkoLS2FwWAwu9e2NUNOJ+Hp3rGQI5vz5Zdfdnlv9uzZvZjEuubNm3fX90h1j0tbg9I2jo6OmDx5Mh544AFBiawjODgY+fn5CA8Px8SJE/HBBx/A3t5e0nvJNBoNNm7ciPHjx3doHivlP19y98knn2DcuHGYP3++rE7zk+VYyJHNqaqqMntdU1ODwsJCBAcHC0rUe6S6x2XWrFmiI/SIJ5980vT1I488giFDhqCxsREPPvigwFSWMRgMpt537f+ske3SarV49NFHZX0AjLqHhRzZnM76cuXn53faIFhupPpLurW1Fd999x1ycnJw8+ZN/Pd//zcKCwtRU1OD0NBQ0fGsRg6PxaXW945uGT9+PAoKCjB69GjRUcjGsJAjSXjwwQexdetW0TGoC1999RUKCgowdepU7N69GwCgVquxb98+yRVy69atu6eCeunSpb2QxvquX7/e5T1vb+9eTEJ3c/ve0+bmZmzevBnDhg3r0KRargfE6N6wkCOb0/4vmqamJpw7d47DoG3YmTNnsGLFCri7u5sKOS8vrzsWDbZKyu1S7sXKlSu7vCf1foZy037vqRzmMpP1sZAjm9P+LxpHR0f4+/vj2WefFZSo90h1j1xrayucnJwA/P54uLGx0XRNSqKiou7r/bt3776ngyy2on2xptPpkJqaKovHxnIj172nZF0s5MjmyHVVYO/evZgzZ06H659//rlpU/0rr7zS27GsYsyYMdi3bx/i4uIA3CrsvvzyS4wbN05wsp537tw5SRVy7alUKsTFxWHVqlUIDw8XHYe6kJ6ejlGjRiEwMNB0raioCD/99BOmTZsmLhgJJ69hliQ7RqPR7B8pO3v2bKfXs7OzTV9LdVXkiSeeQE1NDZYtW4aGhgYsWbIEWq0Wjz32mOhoPU6qq6i3q6ioQFNTk+gYdAeZmZkdHq36+PggMzNTUCKyFVyRI5tzL40vpeT06dMAgJaWFtPXba5fv95hDJkUubi4YOHChaitrcWNGzegVquhUqlEx+oVUjtp3P4wR1NTE8rLyzFz5kyBqehuWlpaYG9vb3bNwcGhw+9I6ntYyJHNkVvjy6ysLAC3fhG3fQ3cKgA8PDxkt/fP3d0dBoPBdNCBJyFtS/vDHG17UAcMGCAoEd2LgIAAnDhxAlOnTjVdO3nypKzH/NG9YSFHNkdujS+XLFkCADh06BAeffRRwWl6Rn5+Pj799FPU1NR0uCfFVdT7IYVHq3ealgIApaWlADjZwZbFxcVhw4YNyMrKQv/+/fHbb7+hpqYGixcvFh2NBGMhRzZHro0vY2Nju9zn1zb0WqpSUlIwc+ZMREVFSX4VdcuWLXjhhRcA3GqrMnHixDu+XwrzZG+f4NDc3Izc3FwMHjwYGo0GVVVVKCoqkvTYsb7Az88PK1euxI8//oiqqioEBwdj7NixcHZ2Fh2NBGMhRzbHYDDIsvHla6+91uU9qa9a1dfXY/LkybJYRS0oKEBraysUCgU+//zzuxZyUjixevs0h61bt+L55583K9xyc3ORm5srIhrdo7ZT72FhYWbXbz/1Tn0TCzmyOb6+vrJsfLl69Wqz1zU1NUhPT5dFi47o6GicOXMG0dHRoqNYbNiwYVi7di0GDBgAg8Fg1l3/dlL9UJGfn4/nnnvO7FpQUBB27twpKBHdi7Nnz3bavig7O5uFXB/HQo5szr00wUxPT8f06dN7IY31eHl5dXj97LPP4r333pP8NIErV67g22+/RUZGRodVVKmNsvqP//gPXLhwAVqtFgqFokN3fanr378/jh8/jpiYGNO1EydOyO6/Uy76wql3sgwLOZIkKRZynWloaEBtba3oGBabNGmS5IvRNkqlEpGRkQBu/eUpt+768+fPx+bNm/H111/D09MT1dXVsLOzw4svvig6GnWir516p/unaJXCkSuidpYsWYKkpCTRMe5L+0d0BoMBhYWFCA0Nxdy5c8WE6kVSG2XVprKyEjk5OaiuroanpyfCwsIk36qjpaUFV65cQXV1NVQqFYYOHdqhRxnZFjmfeifLcEWOJEmKm+rbP7pydHTE5MmT8cADDwhK1LukOMoqLy8PO3bswNixY6HRaFBRUYF3330X8fHxCAoKEh2v2+zt7SU7RaSvur2Ia21tNWt7I/VT72QZFnJEvURuj+julxQX/w8dOoSFCxdi1KhRpms//fQTUlJSJF3IkfRUV1cjJSUFly9fRn19vdk9qZ96J8uwkCNJkmJRANzqS5aVlWV6TBcZGXnX9hZyIcVV1Kqqqg4rV8OGDUN1dbWgRNRX7dq1C46Ojli8eDGSkpKwdOlSHD58GGPGjBEdjQTjeixJkhQfC6WlpSE9PR1hYWGmflAZGRlIS0sTHY264O/vj2+++cbs2jfffAN/f39BiaivunLlCp555hkEBARAoVDA398f8+fP7/DzSX0PV+TIJlVUVKCkpASNjY1m19v6lL3yyisiYlnk9OnTeP31183akDz44INISkrqEwPLpbiKOm/ePCQnJyMzMxNqtRpVVVVwdHTESy+9JDoa9TEKhcK0F87FxQW1tbVwdnbm6jCxkCPbc+TIEaSmpsLf3x9KpdJ0XaFQSLrhbGNjI/r162d2zc3NDU1NTYISWUaOo6za8/HxwVtvvYUrV65Ap9NBpVJhyJAhZic8q6qqoFarBaakviAwMBD5+fkIDg7G6NGjsXXrViiVSgwaNEh0NBKMhRzZnGPHjuGNN96Q3eOr0aNHY/v27fjzn/8MtVoNrVaLQ4cOSXamrBxHWXXmbic8ExMTsX79+l5MRH3R7ZNEnnzySRw9ehSNjY1mjZ2pb2IhRzbH0dERPj4+omNY3dy5c5GSkoJ33nkHLS0tsLe3x4QJEzoduyMFch9lda+k+MiYpMfR0RFpaWnIyckxrQ6HhobC1dVVdDQSjIUc2QSj0Wj6OjY2Fnv37sWsWbM6PIqUcr8kFxcXxMfHY8GCBairq4Obm5uk/3vkPsrqXknxNC5Jz+7du1FZWYk5c+ZAo9FAq9XiyJEj0Ol0eOaZZ0THI4FYyJFNeO211zpc++677zpck3q/pMrKSpw/f97sE7VUpwTIfZQVkS3Jy8vDqlWrTCtwvr6+CAwMxMqVK1nI9XEs5MgmrF69WnSEHnfu3Dns2rULY8aMgUajQVlZGTIyMvD0008jPDxcdDyLxMbGynKUFZGt8PDwQFNTk9mjVIPBAJVKJTAV2QIWcmQTbm/JYTAYYGdnZ3YysKWlxezxqxQdOnQIixYtwogRI0zXLl++jB07dki+kJPrKCuj0XjXx9/cI0c95dKlS6avIyIisHHjRkyZMsXUCuf48eOmVXHqu1jIkc3ZsGEDHnvsMQwZMsR07ddff8XBgwexZMkSgcks09jYiKFDh5pdGzJkiGTbj9xOjqOsjEYjlixZgvfff9+sDU57CQkJvZiK+pJPP/20w7X09HSz1ydPnsS0adN6KxLZIBZyZHNKS0sRGBhodm3w4MEoKSkRE8hKpk6dii+++AKzZ8+GUqlEU1MTvvrqK0ydOlV0NIvJcZSVnZ0dBgwYgLq6Onh6enb5Po1G04upqC9JTEwUHYEkgIUc2RwXFxfU1NSY7f2ora2Fk5OTwFSWO3HiBGpqapCZmQlXV1fU19ejtbUVKpUKJ0+eNL3vnXfeEZiye9pGWd2+MiCHUVbh4eFITk5GTEwMPD09zU6o3r76SEQkiqKVGzzIxuzfvx/FxcWYM2cOvL298dtvv2H//v3w8/NDXFyc6Hjd9tNPP93T+0aOHNnDSazv2rVrSE5ORlNTU4dRVr6+vqLjddudHptytYSIbAELObI5BoMB+/fvx5kzZ9Dc3AwHBwdER0fj8ccfv+NeJRKrpaWFo6yIiHoZCzmyWa2trbh58ybc3d1l0XS1paUFaWlpyMrKMhU7kZGRmDFjBhwc5L/LYenSpZIcZdVWoFZXVyMsLAyNjY0AIPlH/UQkD/L/24MkSY49yf75z3+iqKgI8+bNg5eXF27cuIG0tDTo9XpJPzK+V1L8zFhaWoqPPvoIDg4OpkKusLAQZ8+exQsvvCA6HhERpDsfiGQrLy8P7777Lq5duwZXV1dTT7K8vDzR0Sxy4cIFvPTSSxg9ejQGDhyI0aNHY+HChTh//rzoaL1Ciquqe/bsQWxsLFauXGnqJzdixAj8/PPPgpMREd3CFTmyOXLsSQZIc0WqrysrK0NERASA3wtRJycnGAwGkbGIiEy4Ikc2R449yQBgwoQJSE5OxsWLF1FeXo78/Hxs3rwZEyZMEB2NuuDl5YVff/3V7FpRURH69+8vKBERkTmuyJHNkWtPssceewxpaWlISUkx2/s3Y8YM0dEsJtdRVrNnz8aHH36IyZMno6WlBUeOHMGpU6fw9NNPi45GRASAp1bJBrXvSabVauHk5CTpnmRGoxE7d+7E008/LbsWKvc6ykqr1UpyCkJxcTFOnToFrVYLtVqNf/u3f8OgQYNExyIiAsAVObJBPj4+eOutt+7Yk0xq7OzsUFBQcNdVKymS+yirgIAAzJs3T3QMIqJOcUWObJLRaOxQyEm9CMrIyEBDQwNmzZolu75xGRkZOH/+vOxGWTU3NyMtLQ05OTmmn8W2x+FyW1klImliIUc2p6SkBJs3b0ZzczM8PT1RXV0NBwcHLFy4UNL75FasWIGamhrY2dmZmhy3trZCoVBIcr7q7eQ6ymrnzp2orKzEjBkzoNFooNVqceTIEQwYMADPPPOM6HhERCzkyPa8++67CAsLw0MPPWQqdo4dO4bs7Gz87W9/Ex2v2+40a1WK81X7guXLl2PVqlVwdXU1Xaurq8PKlSvx/vvvC0xGRHSLvJ7vkCxUVlZi6tSppsdzCoUCMTExOHz4sOBk9+/LL7+8p/fJoZCT4ygrDw8PNDU1mRVyBoMBKpVKYCoiot+xkCObM2bMGOTl5SE4ONh0LS8vD2PHjhWYqnuqqqpMXzc3NyM3NxeDBw+GRqNBVVUVioqKEBISIjChdchplNWlS5dMX0dERGDjxo2YMmUK1Go1qqqqcPz4cURGRgpMSET0OxZyZHOMRiO2bduGgIAA01+excXFCAoKwo5G+sp6AAAFDklEQVQdO0zvi4+PF5bxXi1YsMD09datW/H888+bFW65ubnIzc0VEc2q2kZZRUZGYtmyZQBujbL67LPPBCe7f59++mmHa+np6WavT548adbnkIhIFBZyZHP8/Pzg5+dneu3r64vRo0cLTGQd+fn5eO6558yuBQUFYefOnYISWY+cRllJ+XAGEfU9LOTI5syaNQsFBQXIyclBbW0tFi1ahKtXr0Kv10u6lUX//v1x/PhxxMTEmK6dOHFCFuOe2kZZDR482HSNo6yIiHoeCzmyOZmZmfj2228RHR1teuyoVCqxd+9eLF++XHC67ps/fz42b96Mr7/+2tRWxc7ODi+++KLoaBaT6yirkpIS7Nu3DyUlJabDG20tYzZs2CA4HRERCzmyQZmZmfjrX/8KLy8vZGRkALg17aGyslJwMssEBARg1apVppOdKpUKQ4cOlfTEijbjxo3Dq6++ilOnTmH48OHQarV48cUXJT/Katu2bQgJCcGcOXPYAJiIbBILObI5er0earUawO/7rVpaWmRR8Njb22P48OGiY/QIOY6yqqmpQWxsrNmkCiIiW8JCjmzOiBEjkJ6ejpkzZ5quZWZmyqLXmlzJdZRVVFQUzp07ZzrIQURkazjZgWyOTqdDcnIybt68ierqanh7e8PZ2Rkvv/wyG7HaKLmOsqqpqcHatWvh6OiIfv36md17/fXXBaUiIvodCzmySa2trbh69Sq0Wi3UajUGDx4MOzs70bGoC3IdZbVu3To4ODhg/PjxHVYWJ02aJCgVEdHv+GiVbJJCoUBgYCACAwNFR6F7INdRViUlJVi7di0cHPirkohsE387EVG39IVRVsOHD0d5eTkCAgJERyEi6hQfrRJRtyQkJNzT+6Q8KWHPnj24cOECgoODO+yRmz17tqBURES/YyFHRNSFTz75pMt7t8/RJSIShYUcERERkURxjxwRWUyuo6yuX7/e5T1vb+9eTEJE1DmuyBGRxVavXo2QkBCEhoZ2aNPRv39/Qaks98orr3R5b9OmTb2YhIioc1yRIyKLyXWUVftiTafTITU1VbZj1ohIethhlYgs1jbKSu5UKhXi4uLwxRdfiI5CRASAK3JEZAXTpk3D2rVrkZ6eLvtRVhUVFWhqahIdg4gIAAs5IrKCjz/+GN7e3p2OspKydevWmT0ubmxsxLVr1zBz5kyBqYiIfsdCjogsJtdRVu3nqTo6OsLf3x8DBgwQlIiIyJy8fusSkRByHWUVGhqKrKwsFBcXm9qq5OXlAQDi4+MFJiMiuoWFHBFZzMvLCxs2bJDdKKudO3eipKQE48aNg4eHh+g4REQdsJAjIos1NTVh7NixaG5uRlVVleg4VpOfn4/ExES4urqKjkJE1CkWckRkMbnOHdVoNGhubhYdg4ioS5zsQEQWk+soq6NHj+LChQuIiYnp8Gh11KhRglIREf2OhRwRWUyuo6wSEhK6vJeYmNiLSYiIOsdCjois7vZRVuHh4aLjEBHJFkd0EZHVcZQVEVHvYCFHRD2Co6yIiHoeT60SkcU4yoqISAzukSMii509e9bsNUdZERH1DhZyRGQxg8HQYZRVG46yIiLqOXy0SkQW4ygrIiIxWMgRkcU4yoqISAyeWiUii3GUFRGRGNwjR0QW4ygrIiIxWMgRkcU4yoqISAwWckREREQSxT1yRERERBLFQo6IiIhIoljIEREREUkUCzkiIiIiiWIhR0RERCRR/w+OqhAnewBrDQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 612x612 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "I8SJE0gx0SbC"
      },
      "source": [
        "The correlation between variables in one viable way to find the most important\n",
        "hyperparameters. A different approach is given by <code> plot_bars()</code>.\n",
        "Using this function, the metric 'mae' is plotted for different values of the \n",
        "hyperparameters 'number_of_neurons', 'number_of_layers' and 'epoch_number'. As mentioned\n",
        "before, 'mae' seems to decrease for larger values of these hyperparameters (in the\n",
        "specified region of the dictionary).\n",
        "\n",
        "The bar grid cotanins error bars if there is more than one result for the specified\n",
        "hyperparameter set ('number_of_neurons', 'epoch_number', 'number_of_layers'). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "rmMnDYMG0SbD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a22d5da5-6243-4f30-be77-f9d258fec15a"
      },
      "source": [
        "# a four dimensional bar grid\n",
        "analyze_object.plot_bars('number_of_neurons','mae', 'epoch_number', 'number_of_layers')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1253.38x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "2sUSlKj_0SbH"
      },
      "source": [
        "My current output plot is\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/DLR-SC/Hyperparameter_tutorial/master/img/talos_bar.png' \n",
        "width=1300px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "un_GAJAm0SbI"
      },
      "source": [
        "## Tasks ## \n",
        "__Excercise 3:__\n",
        " - Apply the described process to your Talos output. In more detail:\n",
        "    * Find the hyperparameters that have the largest effect on the performance metric.\n",
        "    * Create a 2nd hyperparameter dictionary that further investigates these important hyperparameters\n",
        "    * Use <code> Scan() </code> to investigate the 2nd dictionary in more detail \n",
        "    (use larger values for round_limit than 10).\n",
        "    * Try to find a close-to-optimal model for this specific regression problem. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "NSZHcSoW0SbJ"
      },
      "source": [
        "# your new hyperparameter dictionary\n",
        "param2 = {'number_of_layers' : [1, 2],\n",
        "         'number_of_neurons' : [8, 16, 32, 64],\n",
        "         'epoch_number' : [10, 20, 40, 80],\n",
        "         'dropout_value' : [0.1],\n",
        "         'optimizer' : ['Adam'],\n",
        "         'batch_size' : [2]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "89Lzo_910SbN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad51d471-4998-433a-bde2-7fcfd1ca616e"
      },
      "source": [
        "scan_object2 = talos.Scan(x=train_data,\n",
        "                         y=train_targets,\n",
        "                         model=build_better_model,\n",
        "                         experiment_name='find_optimal_params',\n",
        "                         params=param2,\n",
        "                         round_limit=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [02:05<00:00,  4.20s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9dchIt2E0SbT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "outputId": "642d05fc-9018-469b-ef90-f9dd3e9c985e"
      },
      "source": [
        "# if you want to see the full output of Scan()\n",
        "scan_object2.data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>duration</th>\n",
              "      <th>round_epochs</th>\n",
              "      <th>loss</th>\n",
              "      <th>mae</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>dropout_value</th>\n",
              "      <th>epoch_number</th>\n",
              "      <th>number_of_layers</th>\n",
              "      <th>number_of_neurons</th>\n",
              "      <th>optimizer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11/15/20-170715</td>\n",
              "      <td>11/15/20-170719</td>\n",
              "      <td>3.821452</td>\n",
              "      <td>40</td>\n",
              "      <td>12.252091</td>\n",
              "      <td>2.585072</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11/15/20-170719</td>\n",
              "      <td>11/15/20-170720</td>\n",
              "      <td>1.389243</td>\n",
              "      <td>10</td>\n",
              "      <td>15.531458</td>\n",
              "      <td>2.820368</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11/15/20-170720</td>\n",
              "      <td>11/15/20-170728</td>\n",
              "      <td>7.785090</td>\n",
              "      <td>80</td>\n",
              "      <td>10.793319</td>\n",
              "      <td>2.436336</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>80</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11/15/20-170728</td>\n",
              "      <td>11/15/20-170729</td>\n",
              "      <td>1.213455</td>\n",
              "      <td>10</td>\n",
              "      <td>27.387032</td>\n",
              "      <td>3.820704</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11/15/20-170730</td>\n",
              "      <td>11/15/20-170732</td>\n",
              "      <td>1.976295</td>\n",
              "      <td>20</td>\n",
              "      <td>71.955353</td>\n",
              "      <td>5.948957</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>11/15/20-170732</td>\n",
              "      <td>11/15/20-170734</td>\n",
              "      <td>2.179955</td>\n",
              "      <td>20</td>\n",
              "      <td>24.880264</td>\n",
              "      <td>3.626423</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>11/15/20-170734</td>\n",
              "      <td>11/15/20-170738</td>\n",
              "      <td>3.815507</td>\n",
              "      <td>40</td>\n",
              "      <td>20.543365</td>\n",
              "      <td>3.391571</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>40</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>11/15/20-170738</td>\n",
              "      <td>11/15/20-170749</td>\n",
              "      <td>10.915527</td>\n",
              "      <td>80</td>\n",
              "      <td>7.179930</td>\n",
              "      <td>1.951282</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>80</td>\n",
              "      <td>2</td>\n",
              "      <td>64</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>11/15/20-170749</td>\n",
              "      <td>11/15/20-170750</td>\n",
              "      <td>1.460906</td>\n",
              "      <td>10</td>\n",
              "      <td>50.615593</td>\n",
              "      <td>5.172183</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11/15/20-170751</td>\n",
              "      <td>11/15/20-170758</td>\n",
              "      <td>7.345034</td>\n",
              "      <td>80</td>\n",
              "      <td>12.709488</td>\n",
              "      <td>2.636868</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11/15/20-170758</td>\n",
              "      <td>11/15/20-170801</td>\n",
              "      <td>2.572246</td>\n",
              "      <td>20</td>\n",
              "      <td>9.291753</td>\n",
              "      <td>2.228276</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>64</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11/15/20-170801</td>\n",
              "      <td>11/15/20-170808</td>\n",
              "      <td>7.132258</td>\n",
              "      <td>80</td>\n",
              "      <td>15.356793</td>\n",
              "      <td>2.856802</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>11/15/20-170808</td>\n",
              "      <td>11/15/20-170810</td>\n",
              "      <td>2.061877</td>\n",
              "      <td>20</td>\n",
              "      <td>28.249790</td>\n",
              "      <td>3.876257</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>11/15/20-170810</td>\n",
              "      <td>11/15/20-170815</td>\n",
              "      <td>4.598428</td>\n",
              "      <td>40</td>\n",
              "      <td>12.745881</td>\n",
              "      <td>2.550905</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>40</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>11/15/20-170815</td>\n",
              "      <td>11/15/20-170822</td>\n",
              "      <td>6.960982</td>\n",
              "      <td>80</td>\n",
              "      <td>20.626808</td>\n",
              "      <td>3.292973</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>11/15/20-170822</td>\n",
              "      <td>11/15/20-170824</td>\n",
              "      <td>2.302318</td>\n",
              "      <td>20</td>\n",
              "      <td>15.021291</td>\n",
              "      <td>2.756985</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>11/15/20-170824</td>\n",
              "      <td>11/15/20-170827</td>\n",
              "      <td>2.307065</td>\n",
              "      <td>20</td>\n",
              "      <td>15.728567</td>\n",
              "      <td>2.863504</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>11/15/20-170827</td>\n",
              "      <td>11/15/20-170828</td>\n",
              "      <td>1.318798</td>\n",
              "      <td>10</td>\n",
              "      <td>20.403208</td>\n",
              "      <td>3.212539</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>11/15/20-170828</td>\n",
              "      <td>11/15/20-170832</td>\n",
              "      <td>3.776640</td>\n",
              "      <td>40</td>\n",
              "      <td>22.416620</td>\n",
              "      <td>3.569614</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>11/15/20-170832</td>\n",
              "      <td>11/15/20-170841</td>\n",
              "      <td>8.696728</td>\n",
              "      <td>80</td>\n",
              "      <td>8.683352</td>\n",
              "      <td>2.153363</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>80</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>11/15/20-170841</td>\n",
              "      <td>11/15/20-170849</td>\n",
              "      <td>7.463862</td>\n",
              "      <td>80</td>\n",
              "      <td>14.987596</td>\n",
              "      <td>2.889858</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>80</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>11/15/20-170849</td>\n",
              "      <td>11/15/20-170854</td>\n",
              "      <td>5.009071</td>\n",
              "      <td>40</td>\n",
              "      <td>8.440491</td>\n",
              "      <td>2.027187</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>40</td>\n",
              "      <td>2</td>\n",
              "      <td>64</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>11/15/20-170854</td>\n",
              "      <td>11/15/20-170858</td>\n",
              "      <td>4.118651</td>\n",
              "      <td>40</td>\n",
              "      <td>19.471910</td>\n",
              "      <td>3.200391</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>40</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>11/15/20-170858</td>\n",
              "      <td>11/15/20-170900</td>\n",
              "      <td>2.063814</td>\n",
              "      <td>20</td>\n",
              "      <td>24.014759</td>\n",
              "      <td>3.662426</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>11/15/20-170900</td>\n",
              "      <td>11/15/20-170909</td>\n",
              "      <td>8.609147</td>\n",
              "      <td>80</td>\n",
              "      <td>9.160192</td>\n",
              "      <td>2.187363</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>11/15/20-170909</td>\n",
              "      <td>11/15/20-170913</td>\n",
              "      <td>4.478795</td>\n",
              "      <td>40</td>\n",
              "      <td>10.616565</td>\n",
              "      <td>2.353487</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>11/15/20-170914</td>\n",
              "      <td>11/15/20-170915</td>\n",
              "      <td>1.235255</td>\n",
              "      <td>10</td>\n",
              "      <td>72.955849</td>\n",
              "      <td>5.906415</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>11/15/20-170915</td>\n",
              "      <td>11/15/20-170916</td>\n",
              "      <td>1.313194</td>\n",
              "      <td>10</td>\n",
              "      <td>27.166851</td>\n",
              "      <td>3.899632</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>11/15/20-170916</td>\n",
              "      <td>11/15/20-170919</td>\n",
              "      <td>2.537129</td>\n",
              "      <td>20</td>\n",
              "      <td>11.328819</td>\n",
              "      <td>2.457350</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>11/15/20-170919</td>\n",
              "      <td>11/15/20-170921</td>\n",
              "      <td>1.532653</td>\n",
              "      <td>10</td>\n",
              "      <td>12.316781</td>\n",
              "      <td>2.499694</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>64</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              start              end  ...  number_of_neurons  optimizer\n",
              "0   11/15/20-170715  11/15/20-170719  ...                 32       Adam\n",
              "1   11/15/20-170719  11/15/20-170720  ...                 32       Adam\n",
              "2   11/15/20-170720  11/15/20-170728  ...                 16       Adam\n",
              "3   11/15/20-170728  11/15/20-170729  ...                 32       Adam\n",
              "4   11/15/20-170730  11/15/20-170732  ...                  8       Adam\n",
              "5   11/15/20-170732  11/15/20-170734  ...                  8       Adam\n",
              "6   11/15/20-170734  11/15/20-170738  ...                  8       Adam\n",
              "7   11/15/20-170738  11/15/20-170749  ...                 64       Adam\n",
              "8   11/15/20-170749  11/15/20-170750  ...                 16       Adam\n",
              "9   11/15/20-170751  11/15/20-170758  ...                 32       Adam\n",
              "10  11/15/20-170758  11/15/20-170801  ...                 64       Adam\n",
              "11  11/15/20-170801  11/15/20-170808  ...                 16       Adam\n",
              "12  11/15/20-170808  11/15/20-170810  ...                 16       Adam\n",
              "13  11/15/20-170810  11/15/20-170815  ...                 32       Adam\n",
              "14  11/15/20-170815  11/15/20-170822  ...                  8       Adam\n",
              "15  11/15/20-170822  11/15/20-170824  ...                 64       Adam\n",
              "16  11/15/20-170824  11/15/20-170827  ...                 16       Adam\n",
              "17  11/15/20-170827  11/15/20-170828  ...                 64       Adam\n",
              "18  11/15/20-170828  11/15/20-170832  ...                 16       Adam\n",
              "19  11/15/20-170832  11/15/20-170841  ...                 32       Adam\n",
              "20  11/15/20-170841  11/15/20-170849  ...                  8       Adam\n",
              "21  11/15/20-170849  11/15/20-170854  ...                 64       Adam\n",
              "22  11/15/20-170854  11/15/20-170858  ...                 16       Adam\n",
              "23  11/15/20-170858  11/15/20-170900  ...                 32       Adam\n",
              "24  11/15/20-170900  11/15/20-170909  ...                 64       Adam\n",
              "25  11/15/20-170909  11/15/20-170913  ...                 64       Adam\n",
              "26  11/15/20-170914  11/15/20-170915  ...                  8       Adam\n",
              "27  11/15/20-170915  11/15/20-170916  ...                 16       Adam\n",
              "28  11/15/20-170916  11/15/20-170919  ...                 32       Adam\n",
              "29  11/15/20-170919  11/15/20-170921  ...                 64       Adam\n",
              "\n",
              "[30 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "8YqoB2h80SbX"
      },
      "source": [
        "Your best results are:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ATrdNWsV0SbY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d164be16-a5ea-44fd-c6c6-b5b74411421f"
      },
      "source": [
        "# use Scan object as input\n",
        "analyze_object2 = talos.Analyze(scan_object2)\n",
        "\n",
        "# get the best n=3 paramaters\n",
        "analyze_object2.best_params('mae', ['loss'], n=3, ascending=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Adam', 80, '11/15/20-170749', '11/15/20-170738', 80, 0.1, 64, 2,\n",
              "        10.915526628494263, 2, 0],\n",
              "       ['Adam', 40, '11/15/20-170854', '11/15/20-170849', 40, 0.1, 64, 2,\n",
              "        5.009071350097656, 2, 1],\n",
              "       ['Adam', 80, '11/15/20-170841', '11/15/20-170832', 80, 0.1, 32, 2,\n",
              "        8.696728229522705, 2, 2]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ArcsGo4Z0Sbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9de8132-b69a-4fac-874e-a96f958d306a"
      },
      "source": [
        "# lowest mae with the parameters from analyze_object2.best_params('mae', ['loss'], n=1, ascending=True)\n",
        "analyze_object2.low('mae')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.9512817859649658"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "0ZBNskRG0Sbi"
      },
      "source": [
        "## Deploy close-to-optimal model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeTAXZL70Sbj"
      },
      "source": [
        "### Evaluating Models with <code>Evaluate()</code> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbMw5r3d0Sbk"
      },
      "source": [
        "Models can be evaluated with <code>Evaluate()</code> against a k-fold cross-validation \n",
        "(<code>fold=K</code> specifies the number of repetitions in <code>Evaluate()</code>). \n",
        "Ideally at least 50% of the data, or more if possible, is kept completely out of the <code>Scan</code> process and only exposed into Evaluate once one or more candidate models have been identified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY3PUiTC0Sbk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50893c43-ff64-49fb-a1c6-dfa2fb3bef33"
      },
      "source": [
        "evaluate_object = talos.Evaluate(scan_object2)\n",
        "\n",
        "# returns a list with 'folds=10' outputs\n",
        "all_mae_results =  evaluate_object.evaluate(test_data, test_targets, folds=10, metric='mae', task='continuous')\n",
        "\n",
        "# this is the average 'mae' that gives an aedequate estimation of our model error (on the test data)\n",
        "np.mean(all_mae_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.863247575759887"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUiEajGJ0Sbp"
      },
      "source": [
        "Once a sufficiently performing model has been found, a deployment package can be easily created."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-FVu-aU0Sbp"
      },
      "source": [
        "### Deploying Models with <code>Deploy()</code> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChiOrDcb0Sbq"
      },
      "source": [
        "Once the right model or models have been found, you can create a deployment package with <code>Deploy()</code> which is then easy to transfer to a production or other environment, send via email, or upload to shared remote location. Best model is automatically chosen based on a given metric ('val_acc' by default).\n",
        "\n",
        "The Deploy package is a zip file that consist of: \n",
        "\n",
        "- details of the scan\n",
        "- model weights\n",
        "- model json\n",
        "- results of the experiment\n",
        "- sample of x data\n",
        "- sample of y data\n",
        "\n",
        "The <code>Deploy</code> package can be easily restored with <code>Restore()</code> which is covered in the next section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TApM4tFl0Sbr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acc90085-3587-48d8-c2ab-3373a00df538"
      },
      "source": [
        "# creates a file waw_regression_deploy.zip (\\approx 13 KB) in the local folder \n",
        "# the parameter 'asc' has to be true if lower means better (e.g. loss, mae) but false otherwise (e.g. accuracy)\n",
        "talos.Deploy(scan_object=scan_object2, model_name='waw_regression_deploy', metric='mae', asc=True);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deploy package waw_regression_deploy have been saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Jgb27jS0Sbv"
      },
      "source": [
        "### Restoring Models with <code>Restore()</code>  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt_6xo0l0Sbw"
      },
      "source": [
        "waw_regression = talos.Restore('waw_regression_deploy.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5eNf-r-0Sb2"
      },
      "source": [
        "The <code>Restore</code> object now consists of the assets from the Scan object originally associated with the experiment, together with the model that had been picked as 'best'. The model can be immediately used for making prediction, or use in any other other way Keras model objects can be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "OzhMuUE50Sb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8eeb2a1-4a8c-4f67-b7be-6723b98cdf8a"
      },
      "source": [
        "# What is the 'best' model that we use for predictions?\n",
        "# this should be the same model as found with (better check this) \n",
        "# 'analyze_object2.best_params('mae', ['loss'], n=1, ascending=True)' from the previous cell \n",
        "waw_regression.model.get_config()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'layers': [{'class_name': 'InputLayer',\n",
              "   'config': {'batch_input_shape': (None, 13),\n",
              "    'dtype': 'float32',\n",
              "    'name': 'dense_input',\n",
              "    'ragged': False,\n",
              "    'sparse': False}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'batch_input_shape': (None, 13),\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'dense',\n",
              "    'trainable': True,\n",
              "    'units': 64,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'dense_1',\n",
              "    'trainable': True,\n",
              "    'units': 64,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'Dropout',\n",
              "   'config': {'dtype': 'float32',\n",
              "    'name': 'dropout',\n",
              "    'noise_shape': None,\n",
              "    'rate': 0.1,\n",
              "    'seed': None,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'linear',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'dense_2',\n",
              "    'trainable': True,\n",
              "    'units': 1,\n",
              "    'use_bias': True}}],\n",
              " 'name': 'sequential'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol5JKWmc0Sb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "692d7f81-0b23-4a85-e78e-a12e14959f13"
      },
      "source": [
        "# make predictions with the model\n",
        "# if you are interested, compare the output with the ground truth 'test_targets'\n",
        "waw_regression.model.predict(test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7.9613247],\n",
              "       [19.619656 ],\n",
              "       [20.795305 ],\n",
              "       [30.960594 ],\n",
              "       [23.561115 ],\n",
              "       [22.178398 ],\n",
              "       [25.411566 ],\n",
              "       [20.711662 ],\n",
              "       [21.187153 ],\n",
              "       [21.450752 ],\n",
              "       [20.465988 ],\n",
              "       [17.587511 ],\n",
              "       [17.595005 ],\n",
              "       [41.123318 ],\n",
              "       [20.690517 ],\n",
              "       [19.88621  ],\n",
              "       [24.348907 ],\n",
              "       [18.710955 ],\n",
              "       [18.506676 ],\n",
              "       [22.972752 ],\n",
              "       [11.524115 ],\n",
              "       [16.189232 ],\n",
              "       [20.930891 ],\n",
              "       [14.891711 ],\n",
              "       [17.3449   ],\n",
              "       [23.748592 ],\n",
              "       [28.495794 ],\n",
              "       [27.308002 ],\n",
              "       [11.984704 ],\n",
              "       [19.231815 ],\n",
              "       [19.831715 ],\n",
              "       [17.142982 ],\n",
              "       [28.388605 ],\n",
              "       [23.184956 ],\n",
              "       [20.229576 ],\n",
              "       [ 8.714567 ],\n",
              "       [17.29177  ],\n",
              "       [18.506155 ],\n",
              "       [19.830242 ],\n",
              "       [23.563122 ],\n",
              "       [30.105274 ],\n",
              "       [25.947586 ],\n",
              "       [15.998135 ],\n",
              "       [42.785854 ],\n",
              "       [29.212185 ],\n",
              "       [25.067743 ],\n",
              "       [26.055967 ],\n",
              "       [17.672207 ],\n",
              "       [23.84162  ],\n",
              "       [22.238018 ],\n",
              "       [32.999477 ],\n",
              "       [20.173557 ],\n",
              "       [11.239195 ],\n",
              "       [14.713754 ],\n",
              "       [33.11763  ],\n",
              "       [26.561636 ],\n",
              "       [14.397827 ],\n",
              "       [47.232243 ],\n",
              "       [29.820305 ],\n",
              "       [23.805937 ],\n",
              "       [24.456966 ],\n",
              "       [19.078892 ],\n",
              "       [18.43486  ],\n",
              "       [19.83743  ],\n",
              "       [22.831993 ],\n",
              "       [18.358913 ],\n",
              "       [14.120702 ],\n",
              "       [19.88832  ],\n",
              "       [15.727886 ],\n",
              "       [ 7.642426 ],\n",
              "       [23.852692 ],\n",
              "       [27.711594 ],\n",
              "       [25.7657   ],\n",
              "       [15.074545 ],\n",
              "       [22.524303 ],\n",
              "       [18.794598 ],\n",
              "       [18.80658  ],\n",
              "       [23.874876 ],\n",
              "       [31.972496 ],\n",
              "       [11.028915 ],\n",
              "       [20.878922 ],\n",
              "       [39.252937 ],\n",
              "       [15.136927 ],\n",
              "       [15.42131  ],\n",
              "       [18.341497 ],\n",
              "       [16.907326 ],\n",
              "       [25.90855  ],\n",
              "       [21.725061 ],\n",
              "       [21.96135  ],\n",
              "       [29.72712  ],\n",
              "       [19.70663  ],\n",
              "       [16.64951  ],\n",
              "       [24.806717 ],\n",
              "       [42.53264  ],\n",
              "       [32.57969  ],\n",
              "       [21.459972 ],\n",
              "       [37.758404 ],\n",
              "       [46.799076 ],\n",
              "       [25.41402  ],\n",
              "       [46.744614 ],\n",
              "       [30.702772 ],\n",
              "       [20.624126 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLa-1R2N0Sb_"
      },
      "source": [
        "In addition, for book keeping purpose, and for simplicity of sharing models with team members and other stakeholders, various attributes are included in the <code>Restore</code> object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaDnbXrc0ScA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a66add-d7d7-47a0-af6d-fc5e70e016ec"
      },
      "source": [
        "# get the meta-data for the experiment\n",
        "waw_regression.details"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>experiment_name</td>\n",
              "      <td>find_optimal_params</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>random_method</td>\n",
              "      <td>uniform_mersenne</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>reduction_method</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>reduction_interval</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>reduction_window</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>reduction_threshold</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>reduction_metric</td>\n",
              "      <td>val_acc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>complete_time</td>\n",
              "      <td>11/15/20/17:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>x_shape</td>\n",
              "      <td>(404, 13)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>y_shape</td>\n",
              "      <td>(404,)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      0                    1\n",
              "0                   NaN                    0\n",
              "1       experiment_name  find_optimal_params\n",
              "2         random_method     uniform_mersenne\n",
              "3      reduction_method                  NaN\n",
              "4    reduction_interval                   50\n",
              "5      reduction_window                   20\n",
              "6   reduction_threshold                  0.2\n",
              "7      reduction_metric              val_acc\n",
              "8         complete_time       11/15/20/17:09\n",
              "9               x_shape            (404, 13)\n",
              "10              y_shape               (404,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAryjolD0ScF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5acaaf8e-c5f7-4c7b-ed6a-3747532876da"
      },
      "source": [
        "# get the hyperparameter space boundary, these are the hyperparameter values that you have considered before\n",
        "waw_regression.params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': [2],\n",
              " 'dropout_value': [0.1],\n",
              " 'epoch_number': [10, 20, 40, 80],\n",
              " 'number_of_layers': [1, 2],\n",
              " 'number_of_neurons': [8, 16, 32, 64],\n",
              " 'optimizer': ['Adam']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGglMfqO0ScJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ca1890b-f9a3-4e1b-f4f8-744c528f0b57"
      },
      "source": [
        "# these are the results from the different runs of Scan()\n",
        "waw_regression.results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>duration</th>\n",
              "      <th>round_epochs</th>\n",
              "      <th>loss</th>\n",
              "      <th>mae</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>dropout_value</th>\n",
              "      <th>epoch_number</th>\n",
              "      <th>number_of_layers</th>\n",
              "      <th>number_of_neurons</th>\n",
              "      <th>optimizer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11/15/20-170715</td>\n",
              "      <td>11/15/20-170719</td>\n",
              "      <td>3.821452</td>\n",
              "      <td>40</td>\n",
              "      <td>12.252091</td>\n",
              "      <td>2.585072</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11/15/20-170719</td>\n",
              "      <td>11/15/20-170720</td>\n",
              "      <td>1.389243</td>\n",
              "      <td>10</td>\n",
              "      <td>15.531458</td>\n",
              "      <td>2.820368</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11/15/20-170720</td>\n",
              "      <td>11/15/20-170728</td>\n",
              "      <td>7.785090</td>\n",
              "      <td>80</td>\n",
              "      <td>10.793319</td>\n",
              "      <td>2.436336</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>80</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11/15/20-170728</td>\n",
              "      <td>11/15/20-170729</td>\n",
              "      <td>1.213455</td>\n",
              "      <td>10</td>\n",
              "      <td>27.387032</td>\n",
              "      <td>3.820704</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11/15/20-170730</td>\n",
              "      <td>11/15/20-170732</td>\n",
              "      <td>1.976295</td>\n",
              "      <td>20</td>\n",
              "      <td>71.955353</td>\n",
              "      <td>5.948957</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>11/15/20-170732</td>\n",
              "      <td>11/15/20-170734</td>\n",
              "      <td>2.179955</td>\n",
              "      <td>20</td>\n",
              "      <td>24.880264</td>\n",
              "      <td>3.626423</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>11/15/20-170734</td>\n",
              "      <td>11/15/20-170738</td>\n",
              "      <td>3.815507</td>\n",
              "      <td>40</td>\n",
              "      <td>20.543365</td>\n",
              "      <td>3.391571</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>40</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>11/15/20-170738</td>\n",
              "      <td>11/15/20-170749</td>\n",
              "      <td>10.915527</td>\n",
              "      <td>80</td>\n",
              "      <td>7.179930</td>\n",
              "      <td>1.951282</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>80</td>\n",
              "      <td>2</td>\n",
              "      <td>64</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>11/15/20-170749</td>\n",
              "      <td>11/15/20-170750</td>\n",
              "      <td>1.460906</td>\n",
              "      <td>10</td>\n",
              "      <td>50.615593</td>\n",
              "      <td>5.172183</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11/15/20-170751</td>\n",
              "      <td>11/15/20-170758</td>\n",
              "      <td>7.345034</td>\n",
              "      <td>80</td>\n",
              "      <td>12.709488</td>\n",
              "      <td>2.636868</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11/15/20-170758</td>\n",
              "      <td>11/15/20-170801</td>\n",
              "      <td>2.572246</td>\n",
              "      <td>20</td>\n",
              "      <td>9.291753</td>\n",
              "      <td>2.228276</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>64</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11/15/20-170801</td>\n",
              "      <td>11/15/20-170808</td>\n",
              "      <td>7.132258</td>\n",
              "      <td>80</td>\n",
              "      <td>15.356793</td>\n",
              "      <td>2.856802</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>11/15/20-170808</td>\n",
              "      <td>11/15/20-170810</td>\n",
              "      <td>2.061877</td>\n",
              "      <td>20</td>\n",
              "      <td>28.249790</td>\n",
              "      <td>3.876257</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>11/15/20-170810</td>\n",
              "      <td>11/15/20-170815</td>\n",
              "      <td>4.598428</td>\n",
              "      <td>40</td>\n",
              "      <td>12.745881</td>\n",
              "      <td>2.550905</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>40</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>11/15/20-170815</td>\n",
              "      <td>11/15/20-170822</td>\n",
              "      <td>6.960982</td>\n",
              "      <td>80</td>\n",
              "      <td>20.626808</td>\n",
              "      <td>3.292973</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>11/15/20-170822</td>\n",
              "      <td>11/15/20-170824</td>\n",
              "      <td>2.302318</td>\n",
              "      <td>20</td>\n",
              "      <td>15.021291</td>\n",
              "      <td>2.756985</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>11/15/20-170824</td>\n",
              "      <td>11/15/20-170827</td>\n",
              "      <td>2.307065</td>\n",
              "      <td>20</td>\n",
              "      <td>15.728567</td>\n",
              "      <td>2.863504</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>11/15/20-170827</td>\n",
              "      <td>11/15/20-170828</td>\n",
              "      <td>1.318798</td>\n",
              "      <td>10</td>\n",
              "      <td>20.403208</td>\n",
              "      <td>3.212539</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>11/15/20-170828</td>\n",
              "      <td>11/15/20-170832</td>\n",
              "      <td>3.776640</td>\n",
              "      <td>40</td>\n",
              "      <td>22.416620</td>\n",
              "      <td>3.569614</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>11/15/20-170832</td>\n",
              "      <td>11/15/20-170841</td>\n",
              "      <td>8.696728</td>\n",
              "      <td>80</td>\n",
              "      <td>8.683352</td>\n",
              "      <td>2.153363</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>80</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>11/15/20-170841</td>\n",
              "      <td>11/15/20-170849</td>\n",
              "      <td>7.463862</td>\n",
              "      <td>80</td>\n",
              "      <td>14.987596</td>\n",
              "      <td>2.889858</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>80</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>11/15/20-170849</td>\n",
              "      <td>11/15/20-170854</td>\n",
              "      <td>5.009071</td>\n",
              "      <td>40</td>\n",
              "      <td>8.440491</td>\n",
              "      <td>2.027187</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>40</td>\n",
              "      <td>2</td>\n",
              "      <td>64</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>11/15/20-170854</td>\n",
              "      <td>11/15/20-170858</td>\n",
              "      <td>4.118651</td>\n",
              "      <td>40</td>\n",
              "      <td>19.471910</td>\n",
              "      <td>3.200391</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>40</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>11/15/20-170858</td>\n",
              "      <td>11/15/20-170900</td>\n",
              "      <td>2.063814</td>\n",
              "      <td>20</td>\n",
              "      <td>24.014759</td>\n",
              "      <td>3.662426</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>11/15/20-170900</td>\n",
              "      <td>11/15/20-170909</td>\n",
              "      <td>8.609147</td>\n",
              "      <td>80</td>\n",
              "      <td>9.160192</td>\n",
              "      <td>2.187363</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>11/15/20-170909</td>\n",
              "      <td>11/15/20-170913</td>\n",
              "      <td>4.478795</td>\n",
              "      <td>40</td>\n",
              "      <td>10.616565</td>\n",
              "      <td>2.353487</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>11/15/20-170914</td>\n",
              "      <td>11/15/20-170915</td>\n",
              "      <td>1.235255</td>\n",
              "      <td>10</td>\n",
              "      <td>72.955849</td>\n",
              "      <td>5.906415</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>11/15/20-170915</td>\n",
              "      <td>11/15/20-170916</td>\n",
              "      <td>1.313194</td>\n",
              "      <td>10</td>\n",
              "      <td>27.166851</td>\n",
              "      <td>3.899632</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>11/15/20-170916</td>\n",
              "      <td>11/15/20-170919</td>\n",
              "      <td>2.537129</td>\n",
              "      <td>20</td>\n",
              "      <td>11.328819</td>\n",
              "      <td>2.457350</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>11/15/20-170919</td>\n",
              "      <td>11/15/20-170921</td>\n",
              "      <td>1.532653</td>\n",
              "      <td>10</td>\n",
              "      <td>12.316781</td>\n",
              "      <td>2.499694</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>64</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              start              end  ...  number_of_neurons  optimizer\n",
              "0   11/15/20-170715  11/15/20-170719  ...                 32       Adam\n",
              "1   11/15/20-170719  11/15/20-170720  ...                 32       Adam\n",
              "2   11/15/20-170720  11/15/20-170728  ...                 16       Adam\n",
              "3   11/15/20-170728  11/15/20-170729  ...                 32       Adam\n",
              "4   11/15/20-170730  11/15/20-170732  ...                  8       Adam\n",
              "5   11/15/20-170732  11/15/20-170734  ...                  8       Adam\n",
              "6   11/15/20-170734  11/15/20-170738  ...                  8       Adam\n",
              "7   11/15/20-170738  11/15/20-170749  ...                 64       Adam\n",
              "8   11/15/20-170749  11/15/20-170750  ...                 16       Adam\n",
              "9   11/15/20-170751  11/15/20-170758  ...                 32       Adam\n",
              "10  11/15/20-170758  11/15/20-170801  ...                 64       Adam\n",
              "11  11/15/20-170801  11/15/20-170808  ...                 16       Adam\n",
              "12  11/15/20-170808  11/15/20-170810  ...                 16       Adam\n",
              "13  11/15/20-170810  11/15/20-170815  ...                 32       Adam\n",
              "14  11/15/20-170815  11/15/20-170822  ...                  8       Adam\n",
              "15  11/15/20-170822  11/15/20-170824  ...                 64       Adam\n",
              "16  11/15/20-170824  11/15/20-170827  ...                 16       Adam\n",
              "17  11/15/20-170827  11/15/20-170828  ...                 64       Adam\n",
              "18  11/15/20-170828  11/15/20-170832  ...                 16       Adam\n",
              "19  11/15/20-170832  11/15/20-170841  ...                 32       Adam\n",
              "20  11/15/20-170841  11/15/20-170849  ...                  8       Adam\n",
              "21  11/15/20-170849  11/15/20-170854  ...                 64       Adam\n",
              "22  11/15/20-170854  11/15/20-170858  ...                 16       Adam\n",
              "23  11/15/20-170858  11/15/20-170900  ...                 32       Adam\n",
              "24  11/15/20-170900  11/15/20-170909  ...                 64       Adam\n",
              "25  11/15/20-170909  11/15/20-170913  ...                 64       Adam\n",
              "26  11/15/20-170914  11/15/20-170915  ...                  8       Adam\n",
              "27  11/15/20-170915  11/15/20-170916  ...                 16       Adam\n",
              "28  11/15/20-170916  11/15/20-170919  ...                 32       Adam\n",
              "29  11/15/20-170919  11/15/20-170921  ...                 64       Adam\n",
              "\n",
              "[30 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Wp1N2m-T0ScN"
      },
      "source": [
        "That's almost all on Talos for today. Of course, there are several other routines that are provided by Talos. You find\n",
        "the most recent version (0.6.4 in November 2019) on GitHub (https://github.com/autonomio/talos).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "CX4oOamJ0ScO"
      },
      "source": [
        "### Outlook: a large numbers of hidden layers in Talos\n",
        "\n",
        "You probably have noticed that our model architecture in 'def build_better_model()'\n",
        "can only be used for a relatively low number of hidden layers (since you have to add each layer manually).\n",
        "For a larger number of hidden layers, Talos provides a 'hidden_layers' model \n",
        "(https://github.com/autonomio/talos/blob/master/docs/Hidden_Layers.md). When 'hidden_layers' are used,\n",
        "several parameters must be included in your parameter dictionary. These parameters are \n",
        "'dropout', 'shapes', 'hidden_layers', 'first_neuron' and 'activation'. \n",
        "\n",
        "An application for our problem might look like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cHP7llnL0ScP"
      },
      "source": [
        "param = {'hidden_layers' : [1, 2],          # <--- required\n",
        "         'first_neuron' : [8, 16, 32, 64],  # <--- required\n",
        "         'dropout' : [0, 0.1, 0.2],         # <--- required\n",
        "         'shapes': ['brick'],               # <--- required\n",
        "         'activation': ['relu'],            # <--- required\n",
        "         'epoch_number' : [10, 20, 40, 80],\n",
        "         'optimizer' : ['Adam', 'rmsprop'],\n",
        "         'batch_size' : [1, 2, 4, 8]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "W63OJATy0ScV"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from talos.utils import hidden_layers\n",
        "\n",
        "def build_even_better_model(train_data, train_targets, val_data, val_targets, p):\n",
        "    model = models.Sequential()\n",
        "    \n",
        "    hidden_layers(model, p, 1) # <--- the required arguments are used here\n",
        "        \n",
        "    model.add(layers.Dense(1))\n",
        "    model.compile(optimizer='Adam', loss='mse', metrics=['mae'])\n",
        "    \n",
        "    # make sure history object is returned by model.fit()\n",
        "    history = model.fit(train_data, train_targets, epochs=p['epoch_number'], batch_size=p['batch_size'], verbose=0)\n",
        "    \n",
        "    return history, model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "V8_WNLe40ScZ"
      },
      "source": [
        "## Bonus ## \n",
        "__Excercise 4:__\n",
        " - Use the feature 'hidden_layers' from Talos for a new hyperparameter search.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH81bOVa0Sca"
      },
      "source": [
        "### 3. Guidelines on hyperparameter optimization <a name=\"three\"></a> \n",
        "\n",
        "* Hyperparameter optimization (at least as described in this tutorial with Talos) is an iterative process. You define the\n",
        "hyperparamter boundaries and start a search with <code>Scan()</code>. Using the results, you define new\n",
        "hyperparameter boundaries and a second search, ..., ..., final search.\n",
        "* In most situations, it is not necessary to perform a full grid search on all possible hyperparameter\n",
        "configurations (maybe in the order of thousands). Usually, it is sufficient to perform the scan on \n",
        "a random subset (10-30%).\n",
        "* It is important to determine those hyperparameter that have the largest influence on your performance\n",
        "metric. For this purpose, Talos provides routine such as <code>correlate()</code> to assist you to find these hyperparameters.\n",
        "* All different hyperparameter combinations are evaluated on a validation set. As usual, only your final (after several iterations)\n",
        "model is evaluated with a test set that is independent of the validation set.\n",
        "* Even though Talos can be used analyze thousands of hyperparameter configurations, it is important to\n",
        "first get some kind of intuition/understanding which model architecture might be adequate (e.g. do you require \n",
        "fully connected neural networks?, convolutional neural networks?, what might be the rough number\n",
        "of hidden layers?). Otherwise, since the hyperparameter space grows exponentially you will not be able \n",
        "to evaluate a relevant subset of your high-dimensional hypercube within a reasonable amount of time\n",
        "(cf. Curse of Dimensionality).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2u_DVqN0Scb"
      },
      "source": [
        "Thank you for your participiation! <br>\n",
        "We hope that you have enjoyed this tutorial."
      ]
    }
  ]
}